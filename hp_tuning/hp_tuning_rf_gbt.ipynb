{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "from category_encoders.woe import WOEEncoder\n",
    "from lightgbm import LGBMClassifier, early_stopping, log_evaluation, reset_parameter\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practitioner's Guide to Hyper-Parameter Tuning for Random Forest & GBTs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this notebook is to provide a practical advice on which parameters to tune and which tools to use for HP tuning. This notebook focuses specifically on Random Forest and Gradient Boosted Trees (LightGBM) since these are the models that are used the most in the industry for tabular problems. `Optuna` is used as the main library for tuning since it's model-agnostic and has a very simple API where you just need to specify the optimisation function and all the actual optimisation magic happens behind the scenes. At first, we'll cover some theory and then we'll see the HP tuning in action on a simulated (but very realistic) dataset.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are Hyperparameters?\n",
    "You can think of hyperparameters as levers that you can pull to improve (or degrade) the model. In general (very broad generalization), we have 3 groups of hyperparameters for tree-based ensembles:\n",
    "\n",
    "* Model parameters - affect the structure of the algorithm used to train the model (e.g., maximum depth).\n",
    "* Training parameters - affect the training process of a model (e.g., tolerance).\n",
    "* Ensembling parameters - affect the ensembling logic used in bagging/boosting (e.g., number of trees).\n",
    "\n",
    "Keep in mind that these 3 groups are quite arbitrary, and some parameters might fit into multiple categories. Still, it's a useful framework to have in mind when you explore available hyperparameters. It's always a good idea to go through the model documentation to understand what each parameter does before attempting to tune them.\n",
    "\n",
    "## How to Tune Hyperparameters\n",
    "\n",
    "### Bias-Variance Trade-off\n",
    "Even though tuning parameters of ML models might seem like a dark art of throwing things at a wall and seeing what sticks, there's actually logic to (most of) it. Remember the bias/variance trade-off? The concept that says that as the models get progressively more complex, they can fit more complex data (low bias) but will get more susceptible to fluctuations in the training data (high variance). In contrast, simple models will have high bias and low variance. <br><br>\n",
    "> Hyper-parameter tuning is the process of finding an optimal point in bias-variance trade-off by changing the model (and training) parameters available \n",
    "<br><br>\n",
    "\n",
    "![image](bv_tradeoff.png)\n",
    "\n",
    "Typically, you need 4 components for HP tuning:\n",
    "\n",
    "* Model\n",
    "* Hyperparameter search space\n",
    "* Cross-validation scheme / validation set\n",
    "* Scoring function\n",
    "\n",
    "Picking a model is always the first step since the hyperparameter search space will depend on the model you choose. In this tutorial, we'll focus on Random Forest and LightGBM. You'll see in the following sections how to define an appropriate search space for these two models.\n",
    "\n",
    "### Cross-validation VS Validation Set\n",
    "When it comes to using cross-validation or just a validation set, this will depend on your data size. Working with large data makes it almost impossible to use cross-validation, so a single validation set will have to do. The advantage of cross-validation is that you can get a good estimation of your expected metric because you get a mean and standard deviation from your folds. Using a validation set, you just get a point estimate which can be biased. Hence, **it's important that you don't overfit to your validation set**. This can happen if you keep tuning your model to squeeze the final decimal points of performance. For example, improvement in PR AUC from 0.18 to 0.1805 is not worth it if your hyperparameters stop looking sensible.\n",
    "\n",
    "### Scoring Function\n",
    "This is the metric that you will be optimizing on your validation set. If you choose it incorrectly, all your optimization will go to waste. For example, for binary classification problems, it makes absolutely no sense to optimize for Precision because this will create models that make all the predictions equal to 0. The same with Recall; a perfect Recall score can be achieved if all the predictions are 1. Hence, think wisely about the metric! For binary classification, I prefer to use ROC AUC (or PR AUC for imbalanced problems). For regression models, RMSE usually works quite well (R2 or MAPE are bad choices).\n",
    "\n",
    "### Keep in Mind\n",
    "\n",
    "#### Data Size Effect\n",
    "One important relationship to keep in mind is that **the more data (observations and features) you have, the more complex the model can become**. Note the word \"can\"; it's not necessary that the optimal model will be very complex, but if you have a lot of data, you can experiment with wider ranges of parameters with less risk of overfitting. For example, if you have 1,000 observations and 3 features, it's highly unlikely that the optimal `max_depth` parameter will be 20—you just won't have enough data to avoid overfitting with such a deep tree. On the other hand, with 10,000,000 rows, you can very well end up with a large `max_depth` if the dataset is complicated enough to require it.\n",
    "\n",
    "#### Complicated vs Simple Models\n",
    "Some models are inherently more complex (high variance, low bias)—e.g., Gradient Boosting—and some are inherently simple (low variance, high bias)—e.g., logistic regression. Nevertheless, you can easily tune the more \"complex\" model to have higher bias than the \"simple\" model. For example, a Gradient Boosted Tree with `n_estimators=1` and `max_depth=1` will be simpler than a Decision Tree with `max_depth=20`.\n",
    "\n",
    "Now that you're familiar with these basics, let's jump into a practical part!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "You can get the dataset used in this notebook from [Kaggle](https://www.kaggle.com/datasets/sgpjesus/bank-account-fraud-dataset-neurips-2022). It's quite a good simulation of bank transactions with the main task being fraud detection. It's relatively large and complex, yet it's still manageable to tune on your local laptop. If your laptop struggles with this dataset, it's okay to take a random sample of e.g.  500,000 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pl.read_csv('Base.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\n",
    "    \"payment_type\",\n",
    "    \"employment_status\",\n",
    "    \"housing_status\",\n",
    "    \"source\",\n",
    "    \"device_os\",\n",
    "]\n",
    "numerical_features = [\n",
    "    \"income\",\n",
    "    \"name_email_similarity\",\n",
    "    \"prev_address_months_count\",\n",
    "    \"current_address_months_count\",\n",
    "    \"customer_age\",\n",
    "    \"days_since_request\",\n",
    "    \"intended_balcon_amount\",\n",
    "    \"zip_count_4w\",\n",
    "    \"velocity_6h\",\n",
    "    \"velocity_24h\",\n",
    "    \"velocity_4w\",\n",
    "    \"bank_branch_count_8w\",\n",
    "    \"date_of_birth_distinct_emails_4w\",\n",
    "    \"credit_risk_score\",\n",
    "    \"email_is_free\",\n",
    "    \"phone_home_valid\",\n",
    "    \"phone_mobile_valid\",\n",
    "    \"bank_months_count\",\n",
    "    \"has_other_cards\",\n",
    "    \"proposed_credit_limit\",\n",
    "    \"foreign_request\",\n",
    "    \"session_length_in_minutes\",\n",
    "    \"keep_alive_session\",\n",
    "    \"device_distinct_emails_8w\",\n",
    "    \"device_fraud_count\",\n",
    "]\n",
    "features = numerical_features + categorical_features\n",
    "\n",
    "label = \"fraud_bool\"\n",
    "time_split = \"month\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll perform a time-based split using the `month` variable. This type of split is usually the best at approximating a model's performance on the unseen data that it will encounter after deployment. Note that the choice of a validation set is crucial for HP tuning. If our holdout datasets are not indicative of real data or if they provide a biased image of the model's generalisability, the tuning process will only make our model worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_months = [0, 1, 2, 3, 4]\n",
    "val_months = [5]\n",
    "test_months = [6, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 675666\n",
      "Train fraud samples: 6740\n",
      "\n",
      "Val samples: 119323\n",
      "Val fraud samples: 1411\n",
      "\n",
      "Test samples: 205011\n",
      "Test fraud samples: 2878\n"
     ]
    }
   ],
   "source": [
    "train = data.filter(pl.col(\"month\").is_in(train_months)).to_pandas()\n",
    "print('Train samples:', train.shape[0])\n",
    "print('Train fraud samples:', train['fraud_bool'].sum())\n",
    "\n",
    "val = data.filter(pl.col(\"month\").is_in(val_months)).to_pandas()\n",
    "print('\\nVal samples:', val.shape[0])\n",
    "print('Val fraud samples:', val['fraud_bool'].sum())\n",
    "\n",
    "test = data.filter(pl.col(\"month\").is_in(test_months)).to_pandas()\n",
    "print('\\nTest samples:', test.shape[0])\n",
    "print('Test fraud samples:', test['fraud_bool'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make our life simpler, I'm going to process the categorical variables using Weight-of-Evidence. Having said that, usually, I'd recommend to use the in-built functionality of LightGBM to handle categorical variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = WOEEncoder(cols=categorical_features, drop_invariant=True)\n",
    "enc.fit(train, train[label])\n",
    "\n",
    "train = enc.transform(train)\n",
    "val = enc.transform(val)\n",
    "test = enc.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(675666, 32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "Random Forest is a go-to favourite of many seasoned DS because it requires very little hyperparameter tuning. Still, there are some parameters that we can tweak to make the model more/less regularised. Parameters available:\n",
    "* `n_estimators` -  the number of decision trees in the forest\n",
    "* `max_depth` - maximum depth of a tree in the forest. Higher - more variance, less - more bias\n",
    "* `min_samples_leaf` - minimum samples required to be in a leaf. Higher - more bias, less more vairance\n",
    "* `max_features` - number of features to consider when looking for the best split\n",
    "* `max_samples` - number of samples to draw from X to train a tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(n_jobs=-1)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_jobs=-1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_default = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "rf_default.fit(train[features], train[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base RF Train PR AUC: 0.9999999999999999\n",
      "Base RF Validation PR AUC: 0.12814533948021295\n"
     ]
    }
   ],
   "source": [
    "rf_base_pred_train = rf_default.predict_proba(train[features])[:, 1]\n",
    "rf_base_pred_val = rf_default.predict_proba(val[features])[:, 1]\n",
    "\n",
    "pr_auc_base_val = average_precision_score(val[label], rf_base_pred_val)\n",
    "pr_auc_base_train = average_precision_score(train[label], rf_base_pred_train)\n",
    "\n",
    "print('Base RF Train PR AUC:', pr_auc_base_train)\n",
    "print('Base RF Validation PR AUC:', pr_auc_base_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From train/val performance mismatch we can see that the default parameters will cause your model to severly overfit. No wonder, since we don't really control the depth of our trees and `min_samples_leaf` are set to 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of Num Trees\n",
    "Number of trees makes the model more robust but the benefit is only visible until a certain point. To demonstrate this, let's train a few models with increasing number of trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [08:41<00:00, 74.47s/it] \n"
     ]
    }
   ],
   "source": [
    "num_trees = [10, 50, 100, 200, 300, 500, 1000]\n",
    "pr_aucs = []\n",
    "time_to_train = []\n",
    "\n",
    "for n in tqdm(num_trees):\n",
    "    rf = RandomForestClassifier(n_estimators=n, n_jobs=-1)\n",
    "    t0 = time.time()\n",
    "    rf.fit(train[features], train[label])\n",
    "    t1 = time.time()\n",
    "    preds = rf.predict_proba(val[features])[:, 1]\n",
    "    pr = average_precision_score(val[label], preds)\n",
    "\n",
    "    pr_aucs.append(pr)\n",
    "    time_to_train.append(t1 - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg class=\"main-svg\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"700\" height=\"500\" style=\"\" viewBox=\"0 0 700 500\"><rect x=\"0\" y=\"0\" width=\"700\" height=\"500\" style=\"fill: rgb(255, 255, 255); fill-opacity: 1;\"/><defs id=\"defs-fde228\"><g class=\"clips\"><clipPath id=\"clipfde228xyplot\" class=\"plotclip\"><rect width=\"418.29999999999995\" height=\"320\"/></clipPath><clipPath id=\"clipfde228xy2plot\" class=\"plotclip\"><rect width=\"418.29999999999995\" height=\"320\"/></clipPath><clipPath class=\"axesclip\" id=\"clipfde228x\"><rect x=\"80\" y=\"0\" width=\"418.29999999999995\" height=\"500\"/></clipPath><clipPath class=\"axesclip\" id=\"clipfde228y\"><rect x=\"0\" y=\"100\" width=\"700\" height=\"320\"/></clipPath><clipPath class=\"axesclip\" id=\"clipfde228xy\"><rect x=\"80\" y=\"100\" width=\"418.29999999999995\" height=\"320\"/></clipPath><clipPath class=\"axesclip\" id=\"clipfde228y2\"><rect x=\"0\" y=\"100\" width=\"700\" height=\"320\"/></clipPath><clipPath class=\"axesclip\" id=\"clipfde228xy2\"><rect x=\"80\" y=\"100\" width=\"418.29999999999995\" height=\"320\"/></clipPath></g><g class=\"gradients\"/><g class=\"patterns\"/></defs><g class=\"bglayer\"><rect class=\"bg\" x=\"80\" y=\"100\" width=\"418.29999999999995\" height=\"320\" style=\"fill: rgb(229, 236, 246); fill-opacity: 1; stroke-width: 0;\"/></g><g class=\"layer-below\"><g class=\"imagelayer\"/><g class=\"shapelayer\"/></g><g class=\"cartesianlayer\"><g class=\"subplot xy\"><g class=\"layer-subplot\"><g class=\"shapelayer\"/><g class=\"imagelayer\"/></g><g class=\"minor-gridlayer\"><g class=\"x\"/><g class=\"y\"/><g class=\"y2\"/></g><g class=\"gridlayer\"><g class=\"x\"><path class=\"xgrid crisp\" transform=\"translate(175.48000000000002,0)\" d=\"M0,100v320\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(250.02,0)\" d=\"M0,100v320\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(324.56,0)\" d=\"M0,100v320\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(399.1,0)\" d=\"M0,100v320\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(473.63,0)\" d=\"M0,100v320\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/></g><g class=\"y\"><path class=\"ygrid crisp\" transform=\"translate(0,344.65)\" d=\"M80,0h418.29999999999995\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,285.7)\" d=\"M80,0h418.29999999999995\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,226.74)\" d=\"M80,0h418.29999999999995\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,167.78)\" d=\"M80,0h418.29999999999995\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,108.83)\" d=\"M80,0h418.29999999999995\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/></g><g class=\"y2\"><path class=\"y2grid crisp\" transform=\"translate(0,389.01)\" d=\"M80,0h418.29999999999995\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"y2grid crisp\" transform=\"translate(0,329.2)\" d=\"M80,0h418.29999999999995\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"y2grid crisp\" transform=\"translate(0,269.39)\" d=\"M80,0h418.29999999999995\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"y2grid crisp\" transform=\"translate(0,209.57999999999998)\" d=\"M80,0h418.29999999999995\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"y2grid crisp\" transform=\"translate(0,149.77)\" d=\"M80,0h418.29999999999995\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/></g></g><g class=\"zerolinelayer\"><path class=\"xzl zl crisp\" transform=\"translate(100.94,0)\" d=\"M0,100v320\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 2px;\"/><path class=\"yzl zl crisp\" transform=\"translate(0,403.61)\" d=\"M80,0h418.29999999999995\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 2px;\"/></g><path class=\"xlines-below\"/><path class=\"ylines-below\"/><g class=\"overlines-below\"><path class=\"xy2-x\"/><path class=\"xy2-y\"/></g><g class=\"xaxislayer-below\"/><g class=\"yaxislayer-below\"/><g class=\"overaxes-below\"><g class=\"xy2-x\"/><g class=\"xy2-y\"/></g><g class=\"plot\" transform=\"translate(80,100)\" clip-path=\"url(#clipfde228xyplot)\"><g class=\"scatterlayer mlayer\"><g class=\"trace scatter tracedd02c1\" style=\"stroke-miterlimit: 2; opacity: 1;\"><g class=\"fills\"/><g class=\"errorbars\"/><g class=\"lines\"><path class=\"js-line\" d=\"M24.67,300.25L95.48,247.59L132.75,220.77L207.29,162.13L393.63,19.75\" style=\"vector-effect: none; fill: none; stroke: rgb(99, 110, 250); stroke-opacity: 1; stroke-width: 2px; opacity: 1;\"/></g><g class=\"points\"><path class=\"point\" transform=\"translate(24.67,300.25)\" d=\"M3,0A3,3 0 1,1 0,-3A3,3 0 0,1 3,0Z\" style=\"opacity: 1; stroke-width: 0px; fill: rgb(99, 110, 250); fill-opacity: 1;\"/><path class=\"point\" transform=\"translate(39.57,289.13)\" d=\"M3,0A3,3 0 1,1 0,-3A3,3 0 0,1 3,0Z\" style=\"opacity: 1; stroke-width: 0px; fill: rgb(99, 110, 250); fill-opacity: 1;\"/><path class=\"point\" transform=\"translate(58.21,275.26)\" d=\"M3,0A3,3 0 1,1 0,-3A3,3 0 0,1 3,0Z\" style=\"opacity: 1; stroke-width: 0px; fill: rgb(99, 110, 250); fill-opacity: 1;\"/><path class=\"point\" transform=\"translate(95.48,247.59)\" d=\"M3,0A3,3 0 1,1 0,-3A3,3 0 0,1 3,0Z\" style=\"opacity: 1; stroke-width: 0px; fill: rgb(99, 110, 250); fill-opacity: 1;\"/><path class=\"point\" transform=\"translate(132.75,220.77)\" d=\"M3,0A3,3 0 1,1 0,-3A3,3 0 0,1 3,0Z\" style=\"opacity: 1; stroke-width: 0px; fill: rgb(99, 110, 250); fill-opacity: 1;\"/><path class=\"point\" transform=\"translate(207.29,162.13)\" d=\"M3,0A3,3 0 1,1 0,-3A3,3 0 0,1 3,0Z\" style=\"opacity: 1; stroke-width: 0px; fill: rgb(99, 110, 250); fill-opacity: 1;\"/><path class=\"point\" transform=\"translate(393.63,19.75)\" d=\"M3,0A3,3 0 1,1 0,-3A3,3 0 0,1 3,0Z\" style=\"opacity: 1; stroke-width: 0px; fill: rgb(99, 110, 250); fill-opacity: 1;\"/></g><g class=\"text\"/></g></g></g><g class=\"overplot\"><g class=\"xy2\" transform=\"translate(80,100)\" clip-path=\"url(#clipfde228xy2plot)\"><g class=\"scatterlayer mlayer\"><g class=\"trace scatter trace27d1c5\" style=\"stroke-miterlimit: 2; opacity: 1;\"><g class=\"fills\"/><g class=\"errorbars\"/><g class=\"lines\"><path class=\"js-line\" d=\"M24.67,300.25L39.57,132.32L58.21,86.64L95.48,52.77L132.75,30.3L207.29,38.17L393.63,19.75\" style=\"vector-effect: none; fill: none; stroke: rgb(239, 85, 59); stroke-opacity: 1; stroke-width: 2px; opacity: 1;\"/></g><g class=\"points\"><path class=\"point\" transform=\"translate(24.67,300.25)\" d=\"M3,0A3,3 0 1,1 0,-3A3,3 0 0,1 3,0Z\" style=\"opacity: 1; stroke-width: 0px; fill: rgb(239, 85, 59); fill-opacity: 1;\"/><path class=\"point\" transform=\"translate(39.57,132.32)\" d=\"M3,0A3,3 0 1,1 0,-3A3,3 0 0,1 3,0Z\" style=\"opacity: 1; stroke-width: 0px; fill: rgb(239, 85, 59); fill-opacity: 1;\"/><path class=\"point\" transform=\"translate(58.21,86.64)\" d=\"M3,0A3,3 0 1,1 0,-3A3,3 0 0,1 3,0Z\" style=\"opacity: 1; stroke-width: 0px; fill: rgb(239, 85, 59); fill-opacity: 1;\"/><path class=\"point\" transform=\"translate(95.48,52.77)\" d=\"M3,0A3,3 0 1,1 0,-3A3,3 0 0,1 3,0Z\" style=\"opacity: 1; stroke-width: 0px; fill: rgb(239, 85, 59); fill-opacity: 1;\"/><path class=\"point\" transform=\"translate(132.75,30.3)\" d=\"M3,0A3,3 0 1,1 0,-3A3,3 0 0,1 3,0Z\" style=\"opacity: 1; stroke-width: 0px; fill: rgb(239, 85, 59); fill-opacity: 1;\"/><path class=\"point\" transform=\"translate(207.29,38.17)\" d=\"M3,0A3,3 0 1,1 0,-3A3,3 0 0,1 3,0Z\" style=\"opacity: 1; stroke-width: 0px; fill: rgb(239, 85, 59); fill-opacity: 1;\"/><path class=\"point\" transform=\"translate(393.63,19.75)\" d=\"M3,0A3,3 0 1,1 0,-3A3,3 0 0,1 3,0Z\" style=\"opacity: 1; stroke-width: 0px; fill: rgb(239, 85, 59); fill-opacity: 1;\"/></g><g class=\"text\"/></g></g></g></g><path class=\"xlines-above crisp\" d=\"M0,0\" style=\"fill: none;\"/><path class=\"ylines-above crisp\" d=\"M0,0\" style=\"fill: none;\"/><g class=\"overlines-above\"><path class=\"xy2-x crisp\" d=\"M0,0\" style=\"fill: none;\"/><path class=\"xy2-y crisp\" d=\"M0,0\" style=\"fill: none;\"/></g><g class=\"xaxislayer-above\"><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"433\" transform=\"translate(100.94,0)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\">0</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"433\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(175.48000000000002,0)\">200</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"433\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(250.02,0)\">400</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"433\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(324.56,0)\">600</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"433\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(399.1,0)\">800</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"433\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(473.63,0)\">1000</text></g></g><g class=\"yaxislayer-above\"><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" transform=\"translate(0,403.61)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\">0</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(0,344.65)\">50</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(0,285.7)\">100</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(0,226.74)\">150</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(0,167.78)\">200</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(0,108.83)\">250</text></g></g><g class=\"overaxes-above\"><g class=\"xy2-x\"/><g class=\"xy2-y\"><g class=\"y2tick\"><text text-anchor=\"start\" x=\"499.29999999999995\" y=\"4.199999999999999\" transform=\"translate(0,389.01)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\">0.06</text></g><g class=\"y2tick\"><text text-anchor=\"start\" x=\"499.29999999999995\" y=\"4.199999999999999\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(0,329.2)\">0.08</text></g><g class=\"y2tick\"><text text-anchor=\"start\" x=\"499.29999999999995\" y=\"4.199999999999999\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(0,269.39)\">0.1</text></g><g class=\"y2tick\"><text text-anchor=\"start\" x=\"499.29999999999995\" y=\"4.199999999999999\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(0,209.57999999999998)\">0.12</text></g><g class=\"y2tick\"><text text-anchor=\"start\" x=\"499.29999999999995\" y=\"4.199999999999999\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(0,149.77)\">0.14</text></g></g></g></g><g class=\"subplot xy2\"/></g><g class=\"polarlayer\"/><g class=\"smithlayer\"/><g class=\"ternarylayer\"/><g class=\"geolayer\"/><g class=\"funnelarealayer\"/><g class=\"pielayer\"/><g class=\"iciclelayer\"/><g class=\"treemaplayer\"/><g class=\"sunburstlayer\"/><g class=\"glimages\"/><defs id=\"topdefs-fde228\"><g class=\"clips\"/><clipPath id=\"legendfde228\"><rect width=\"154\" height=\"48\" x=\"0\" y=\"0\"/></clipPath></defs><g class=\"layer-above\"><g class=\"imagelayer\"/><g class=\"shapelayer\"/></g><g class=\"infolayer\"><g class=\"legend\" pointer-events=\"all\" transform=\"translate(533.9000000000001,100)\"><rect class=\"bg\" shape-rendering=\"crispEdges\" style=\"stroke: rgb(68, 68, 68); stroke-opacity: 1; fill: rgb(255, 255, 255); fill-opacity: 1; stroke-width: 0px;\" width=\"154\" height=\"48\" x=\"0\" y=\"0\"/><g class=\"scrollbox\" transform=\"\" clip-path=\"url(#legendfde228)\"><g class=\"groups\"><g class=\"traces\" transform=\"translate(0,14.5)\" style=\"opacity: 1;\"><text class=\"legendtext\" text-anchor=\"start\" x=\"40\" y=\"4.680000000000001\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">Seconds to Train</text><g class=\"layers\" style=\"opacity: 1;\"><g class=\"legendfill\"/><g class=\"legendlines\"><path class=\"js-line\" d=\"M5,0h30\" style=\"fill: none; stroke: rgb(99, 110, 250); stroke-opacity: 1; stroke-width: 2px;\"/></g><g class=\"legendsymbols\"><g class=\"legendpoints\"><path class=\"scatterpts\" transform=\"translate(20,0)\" d=\"M3,0A3,3 0 1,1 0,-3A3,3 0 0,1 3,0Z\" style=\"opacity: 1; stroke-width: 0px; fill: rgb(99, 110, 250); fill-opacity: 1;\"/></g></g></g><rect class=\"legendtoggle\" x=\"0\" y=\"-9.5\" width=\"148.96875\" height=\"19\" style=\"fill: rgb(0, 0, 0); fill-opacity: 0;\"/></g><g class=\"traces\" transform=\"translate(0,33.5)\" style=\"opacity: 1;\"><text class=\"legendtext\" text-anchor=\"start\" x=\"40\" y=\"4.680000000000001\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">Validation PR AUC</text><g class=\"layers\" style=\"opacity: 1;\"><g class=\"legendfill\"/><g class=\"legendlines\"><path class=\"js-line\" d=\"M5,0h30\" style=\"fill: none; stroke: rgb(239, 85, 59); stroke-opacity: 1; stroke-width: 2px;\"/></g><g class=\"legendsymbols\"><g class=\"legendpoints\"><path class=\"scatterpts\" transform=\"translate(20,0)\" d=\"M3,0A3,3 0 1,1 0,-3A3,3 0 0,1 3,0Z\" style=\"opacity: 1; stroke-width: 0px; fill: rgb(239, 85, 59); fill-opacity: 1;\"/></g></g></g><rect class=\"legendtoggle\" x=\"0\" y=\"-9.5\" width=\"148.96875\" height=\"19\" style=\"fill: rgb(0, 0, 0); fill-opacity: 0;\"/></g></g></g><rect class=\"scrollbar\" rx=\"20\" ry=\"3\" width=\"0\" height=\"0\" style=\"fill: rgb(128, 139, 164); fill-opacity: 1;\" x=\"0\" y=\"0\"/></g><g class=\"g-gtitle\"><text class=\"gtitle\" x=\"35\" y=\"50\" text-anchor=\"start\" dy=\"0em\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 17px; fill: rgb(42, 63, 95); opacity: 1; font-weight: normal; white-space: pre;\">Valdiation PR AUC &amp; Time to Train vs Number of Trees</text></g><g class=\"g-xtitle\"><text class=\"xtitle\" x=\"289.15\" y=\"459.8\" text-anchor=\"middle\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 14px; fill: rgb(42, 63, 95); opacity: 1; font-weight: normal; white-space: pre;\">Number of Trees</text></g><g class=\"g-ytitle\"><text class=\"ytitle\" transform=\"rotate(-90,31.809375000000003,260)\" x=\"31.809375000000003\" y=\"260\" text-anchor=\"middle\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 14px; fill: rgb(42, 63, 95); opacity: 1; font-weight: normal; white-space: pre;\"><tspan style=\"font-weight:bold\">Seconds</tspan></text></g><g class=\"g-y2title\"><text class=\"y2title\" transform=\"rotate(-90,550.8625,260)\" x=\"550.8625\" y=\"260\" text-anchor=\"middle\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 14px; fill: rgb(42, 63, 95); opacity: 1; font-weight: normal; white-space: pre;\"><tspan style=\"font-weight:bold\">PR AUC</tspan></text></g></g></svg>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create figure with secondary y-axis\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=num_trees, y=time_to_train, name=\"Seconds to Train\"),\n",
    "    secondary_y=False,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=num_trees, y=pr_aucs, name=\"Validation PR AUC\"),\n",
    "    secondary_y=True,\n",
    ")\n",
    "fig.update_layout(\n",
    "    title_text=\"Valdiation PR AUC & Time to Train vs Number of Trees\"\n",
    ")\n",
    "fig.update_xaxes(title_text=\"Number of Trees\")\n",
    "fig.update_yaxes(title_text=\"<b>Seconds</b>\", secondary_y=False)\n",
    "fig.update_yaxes(title_text=\"<b>PR AUC</b>\", secondary_y=True)\n",
    "\n",
    "fig.show(renderer=\"svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, improvements in performance is only up until a certain point (200 trees). After that mark, the performance stays relatively constant but the training speed increases. Keep in mind that the optimal number of trees will be different for every dataset, but it will rarely be as high as 1000. In practice, setting `num_trees` to 300 should be enough in most of the cases. If you're short on time, 100 will work fine as well.\n",
    "\n",
    "\n",
    "Now, let's try to tune all the other parameters mentioned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-06 16:58:31,615] A new study created in memory with name: no-name-e8dac46d-86d2-48f5-ae2a-69ee3cfd7388\n",
      "[I 2024-06-06 17:00:35,967] Trial 0 finished with value: 0.15704485656482786 and parameters: {'max_depth': 20, 'min_samples_leaf': 51, 'max_features': 0.6356999116426916, 'max_samples': 0.6270381157684181}. Best is trial 0 with value: 0.15704485656482786.\n",
      "[I 2024-06-06 17:01:33,800] Trial 1 finished with value: 0.15446428742287244 and parameters: {'max_depth': 15, 'min_samples_leaf': 36, 'max_features': 0.5359931959399997, 'max_samples': 0.3773420731911866}. Best is trial 0 with value: 0.15704485656482786.\n",
      "[I 2024-06-06 17:02:18,591] Trial 2 finished with value: 0.1100311561482043 and parameters: {'max_depth': 4, 'min_samples_leaf': 87, 'max_features': 0.8520804042246046, 'max_samples': 0.6606451873641764}. Best is trial 0 with value: 0.15704485656482786.\n",
      "[I 2024-06-06 17:03:44,701] Trial 3 finished with value: 0.15378832280024743 and parameters: {'max_depth': 18, 'min_samples_leaf': 98, 'max_features': 0.5156217696047471, 'max_samples': 0.6454435894885815}. Best is trial 0 with value: 0.15704485656482786.\n",
      "[I 2024-06-06 17:06:30,692] Trial 4 finished with value: 0.15087137312396365 and parameters: {'max_depth': 20, 'min_samples_leaf': 66, 'max_features': 0.8912966434700824, 'max_samples': 0.6501886022790898}. Best is trial 0 with value: 0.15704485656482786.\n",
      "[I 2024-06-06 17:07:50,089] Trial 5 finished with value: 0.1528990143930421 and parameters: {'max_depth': 19, 'min_samples_leaf': 15, 'max_features': 0.5264379192608464, 'max_samples': 0.5041720269933443}. Best is trial 0 with value: 0.15704485656482786.\n",
      "[I 2024-06-06 17:09:00,682] Trial 6 finished with value: 0.13583485598722042 and parameters: {'max_depth': 7, 'min_samples_leaf': 75, 'max_features': 0.8710681078096869, 'max_samples': 0.5463096651214446}. Best is trial 0 with value: 0.15704485656482786.\n",
      "[I 2024-06-06 17:09:39,300] Trial 7 finished with value: 0.15639254180679707 and parameters: {'max_depth': 10, 'min_samples_leaf': 80, 'max_features': 0.24206740913267832, 'max_samples': 0.8720630083435579}. Best is trial 0 with value: 0.15704485656482786.\n",
      "[I 2024-06-06 17:10:35,544] Trial 8 finished with value: 0.15997846948020542 and parameters: {'max_depth': 16, 'min_samples_leaf': 39, 'max_features': 0.295816908484384, 'max_samples': 0.8314000365985812}. Best is trial 8 with value: 0.15997846948020542.\n",
      "[I 2024-06-06 17:10:51,189] Trial 9 finished with value: 0.12661794347228703 and parameters: {'max_depth': 5, 'min_samples_leaf': 96, 'max_features': 0.2832374301184223, 'max_samples': 0.4821517194520425}. Best is trial 8 with value: 0.15997846948020542.\n",
      "[I 2024-06-06 17:12:13,353] Trial 10 finished with value: 0.1573808901188059 and parameters: {'max_depth': 14, 'min_samples_leaf': 29, 'max_features': 0.3755040803537616, 'max_samples': 0.9814949532234907}. Best is trial 8 with value: 0.15997846948020542.\n",
      "[I 2024-06-06 17:13:34,781] Trial 11 finished with value: 0.159413786763718 and parameters: {'max_depth': 14, 'min_samples_leaf': 28, 'max_features': 0.3767926327404436, 'max_samples': 0.9948818022225332}. Best is trial 8 with value: 0.15997846948020542.\n",
      "[I 2024-06-06 17:14:42,098] Trial 12 finished with value: 0.1599909243760177 and parameters: {'max_depth': 14, 'min_samples_leaf': 45, 'max_features': 0.3571366519273563, 'max_samples': 0.8449836712994356}. Best is trial 12 with value: 0.1599909243760177.\n",
      "[I 2024-06-06 17:15:32,211] Trial 13 finished with value: 0.1557757005413408 and parameters: {'max_depth': 11, 'min_samples_leaf': 51, 'max_features': 0.3259675393925344, 'max_samples': 0.8201724562694434}. Best is trial 12 with value: 0.1599909243760177.\n",
      "[I 2024-06-06 17:17:01,106] Trial 14 finished with value: 0.15795731626460263 and parameters: {'max_depth': 16, 'min_samples_leaf': 41, 'max_features': 0.4452108142884399, 'max_samples': 0.7805199852317906}. Best is trial 12 with value: 0.1599909243760177.\n",
      "[I 2024-06-06 17:17:41,471] Trial 15 finished with value: 0.15967296442609702 and parameters: {'max_depth': 12, 'min_samples_leaf': 11, 'max_features': 0.2040041841807869, 'max_samples': 0.8842324428507019}. Best is trial 12 with value: 0.1599909243760177.\n",
      "[I 2024-06-06 17:19:51,003] Trial 16 finished with value: 0.1560215908607051 and parameters: {'max_depth': 17, 'min_samples_leaf': 62, 'max_features': 0.6195868090972851, 'max_samples': 0.7543629886693407}. Best is trial 12 with value: 0.1599909243760177.\n",
      "[I 2024-06-06 17:20:54,644] Trial 17 finished with value: 0.14933245925105038 and parameters: {'max_depth': 9, 'min_samples_leaf': 45, 'max_features': 0.43554892940925866, 'max_samples': 0.910454963417049}. Best is trial 12 with value: 0.1599909243760177.\n",
      "[I 2024-06-06 17:21:15,880] Trial 18 finished with value: 0.09682136297668814 and parameters: {'max_depth': 2, 'min_samples_leaf': 23, 'max_features': 0.7551599926203401, 'max_samples': 0.709610795288957}. Best is trial 12 with value: 0.1599909243760177.\n",
      "[I 2024-06-06 17:22:09,417] Trial 19 finished with value: 0.15804787334675602 and parameters: {'max_depth': 12, 'min_samples_leaf': 61, 'max_features': 0.3113354150574383, 'max_samples': 0.8164648269121807}. Best is trial 12 with value: 0.1599909243760177.\n",
      "[I 2024-06-06 17:23:36,953] Trial 20 finished with value: 0.1552105977822018 and parameters: {'max_depth': 13, 'min_samples_leaf': 37, 'max_features': 0.4363691522168861, 'max_samples': 0.9307557987142829}. Best is trial 12 with value: 0.1599909243760177.\n",
      "[I 2024-06-06 17:24:24,111] Trial 21 finished with value: 0.1609038906686585 and parameters: {'max_depth': 16, 'min_samples_leaf': 11, 'max_features': 0.20554221042867304, 'max_samples': 0.8691465948377968}. Best is trial 21 with value: 0.1609038906686585.\n",
      "[I 2024-06-06 17:25:11,476] Trial 22 finished with value: 0.16290358141340383 and parameters: {'max_depth': 16, 'min_samples_leaf': 20, 'max_features': 0.2044650100506193, 'max_samples': 0.850091004879685}. Best is trial 22 with value: 0.16290358141340383.\n",
      "[I 2024-06-06 17:25:56,824] Trial 23 finished with value: 0.16206915682328865 and parameters: {'max_depth': 17, 'min_samples_leaf': 17, 'max_features': 0.20256123025135586, 'max_samples': 0.7444805541218292}. Best is trial 22 with value: 0.16290358141340383.\n",
      "[I 2024-06-06 17:26:38,761] Trial 24 finished with value: 0.16274250052780026 and parameters: {'max_depth': 18, 'min_samples_leaf': 18, 'max_features': 0.2076420047267406, 'max_samples': 0.7342469844669617}. Best is trial 22 with value: 0.16290358141340383.\n",
      "[I 2024-06-06 17:27:29,104] Trial 25 finished with value: 0.1617433189161623 and parameters: {'max_depth': 18, 'min_samples_leaf': 20, 'max_features': 0.25510610964380565, 'max_samples': 0.7201134336936597}. Best is trial 22 with value: 0.16290358141340383.\n",
      "[I 2024-06-06 17:28:13,004] Trial 26 finished with value: 0.16432274697649632 and parameters: {'max_depth': 18, 'min_samples_leaf': 22, 'max_features': 0.2184819329961851, 'max_samples': 0.7620655467872154}. Best is trial 26 with value: 0.16432274697649632.\n",
      "[I 2024-06-06 17:28:52,604] Trial 27 finished with value: 0.1614474544885339 and parameters: {'max_depth': 19, 'min_samples_leaf': 28, 'max_features': 0.2572605336430249, 'max_samples': 0.573594660063581}. Best is trial 26 with value: 0.16432274697649632.\n",
      "[I 2024-06-06 17:29:54,216] Trial 28 finished with value: 0.15848175709612697 and parameters: {'max_depth': 18, 'min_samples_leaf': 23, 'max_features': 0.32460053268089334, 'max_samples': 0.6993744956657246}. Best is trial 26 with value: 0.16432274697649632.\n",
      "[I 2024-06-06 17:32:20,992] Trial 29 finished with value: 0.1537036527679002 and parameters: {'max_depth': 20, 'min_samples_leaf': 31, 'max_features': 0.663509272522192, 'max_samples': 0.7807838178611822}. Best is trial 26 with value: 0.16432274697649632.\n",
      "[I 2024-06-06 17:33:34,139] Trial 30 finished with value: 0.15674757704210684 and parameters: {'max_depth': 20, 'min_samples_leaf': 17, 'max_features': 0.4011911861877477, 'max_samples': 0.5918599824980498}. Best is trial 26 with value: 0.16432274697649632.\n",
      "[I 2024-06-06 17:34:19,810] Trial 31 finished with value: 0.16010454000503826 and parameters: {'max_depth': 17, 'min_samples_leaf': 10, 'max_features': 0.20535662291731344, 'max_samples': 0.7769976470747095}. Best is trial 26 with value: 0.16432274697649632.\n",
      "[I 2024-06-06 17:34:43,049] Trial 32 finished with value: 0.16012015263041696 and parameters: {'max_depth': 15, 'min_samples_leaf': 21, 'max_features': 0.2579633996503206, 'max_samples': 0.32704657859568786}. Best is trial 26 with value: 0.16432274697649632.\n",
      "[I 2024-06-06 17:35:24,951] Trial 33 finished with value: 0.16229037565313395 and parameters: {'max_depth': 17, 'min_samples_leaf': 33, 'max_features': 0.23214253644848012, 'max_samples': 0.739270739447042}. Best is trial 26 with value: 0.16432274697649632.\n",
      "[I 2024-06-06 17:37:45,295] Trial 34 finished with value: 0.16255625986211486 and parameters: {'max_depth': 19, 'min_samples_leaf': 34, 'max_features': 0.2513206999528398, 'max_samples': 0.6844608649225201}. Best is trial 26 with value: 0.16432274697649632.\n",
      "[I 2024-06-06 17:44:09,122] Trial 35 finished with value: 0.16217440745033296 and parameters: {'max_depth': 19, 'min_samples_leaf': 25, 'max_features': 0.28283017397671334, 'max_samples': 0.6725729948186985}. Best is trial 26 with value: 0.16432274697649632.\n",
      "[I 2024-06-06 17:47:57,148] Trial 36 finished with value: 0.15476639021916005 and parameters: {'max_depth': 19, 'min_samples_leaf': 16, 'max_features': 0.4875549710915934, 'max_samples': 0.6609253324007119}. Best is trial 26 with value: 0.16432274697649632.\n",
      "[I 2024-06-06 17:49:32,480] Trial 37 finished with value: 0.1561263453687554 and parameters: {'max_depth': 15, 'min_samples_leaf': 36, 'max_features': 0.5900017856563469, 'max_samples': 0.6039914550127442}. Best is trial 26 with value: 0.16432274697649632.\n",
      "[I 2024-06-06 17:50:35,994] Trial 38 finished with value: 0.16121869023174223 and parameters: {'max_depth': 18, 'min_samples_leaf': 44, 'max_features': 0.35111821516374775, 'max_samples': 0.6852319105045563}. Best is trial 26 with value: 0.16432274697649632.\n",
      "[I 2024-06-06 17:52:17,692] Trial 39 finished with value: 0.15365256354211043 and parameters: {'max_depth': 20, 'min_samples_leaf': 52, 'max_features': 0.7262664075322522, 'max_samples': 0.4552828403846019}. Best is trial 26 with value: 0.16432274697649632.\n",
      "[I 2024-06-06 17:53:00,970] Trial 40 finished with value: 0.16092287719099832 and parameters: {'max_depth': 18, 'min_samples_leaf': 33, 'max_features': 0.28234141926329254, 'max_samples': 0.5264212002773346}. Best is trial 26 with value: 0.16432274697649632.\n",
      "[I 2024-06-06 17:53:44,215] Trial 41 finished with value: 0.16469003900807067 and parameters: {'max_depth': 17, 'min_samples_leaf': 33, 'max_features': 0.24347427803049831, 'max_samples': 0.6308326604955227}. Best is trial 41 with value: 0.16469003900807067.\n",
      "[I 2024-06-06 17:54:25,984] Trial 42 finished with value: 0.16396738395829868 and parameters: {'max_depth': 16, 'min_samples_leaf': 26, 'max_features': 0.23533342772640745, 'max_samples': 0.6256666674742581}. Best is trial 41 with value: 0.16469003900807067.\n",
      "[I 2024-06-06 17:55:03,273] Trial 43 finished with value: 0.16154878711473014 and parameters: {'max_depth': 15, 'min_samples_leaf': 26, 'max_features': 0.23313396768509012, 'max_samples': 0.6174969743260489}. Best is trial 41 with value: 0.16469003900807067.\n",
      "[I 2024-06-06 17:55:52,285] Trial 44 finished with value: 0.16042137089363154 and parameters: {'max_depth': 16, 'min_samples_leaf': 19, 'max_features': 0.2991620336008931, 'max_samples': 0.6416081352208957}. Best is trial 41 with value: 0.16469003900807067.\n",
      "[I 2024-06-06 17:56:12,573] Trial 45 finished with value: 0.14830661552028768 and parameters: {'max_depth': 8, 'min_samples_leaf': 14, 'max_features': 0.23004479818210793, 'max_samples': 0.45579953131689366}. Best is trial 41 with value: 0.16469003900807067.\n",
      "[I 2024-06-06 17:56:58,858] Trial 46 finished with value: 0.1585224608119825 and parameters: {'max_depth': 13, 'min_samples_leaf': 25, 'max_features': 0.3288337845436541, 'max_samples': 0.5702011176750466}. Best is trial 41 with value: 0.16469003900807067.\n",
      "[I 2024-06-06 17:57:56,901] Trial 47 finished with value: 0.16143490464682517 and parameters: {'max_depth': 16, 'min_samples_leaf': 30, 'max_features': 0.2810997487502982, 'max_samples': 0.8087013756750222}. Best is trial 41 with value: 0.16469003900807067.\n",
      "[I 2024-06-06 18:00:59,351] Trial 48 finished with value: 0.1491983137244277 and parameters: {'max_depth': 14, 'min_samples_leaf': 14, 'max_features': 0.8287725951829925, 'max_samples': 0.9633541468928595}. Best is trial 41 with value: 0.16469003900807067.\n",
      "[I 2024-06-06 18:01:37,616] Trial 49 finished with value: 0.16211933348090193 and parameters: {'max_depth': 17, 'min_samples_leaf': 41, 'max_features': 0.22928326841662008, 'max_samples': 0.6383544067347644}. Best is trial 41 with value: 0.16469003900807067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "Value: 0.1647\n",
      "Params: \n",
      "    max_depth: 17\n",
      "    min_samples_leaf: 33\n",
      "    max_features: 0.24347427803049831\n",
      "    max_samples: 0.6308326604955227\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 10, 100)\n",
    "    max_features = trial.suggest_float('max_features', 0.2, 0.9)\n",
    "    max_samples = trial.suggest_float('max_samples', 0.3, 1)\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=max_depth,\n",
    "        max_samples=max_samples,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    model.fit(train[features], train[label])\n",
    "    preds = model.predict_proba(val[features])[:, 1]\n",
    "    pr = average_precision_score(val[label], preds)\n",
    "    \n",
    "    return pr\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Print the best parameters found \n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"Value: {:.4f}\".format(trial.value))\n",
    "\n",
    "print(\"Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned RF Train PR AUC: 0.28008855385455533\n",
      "Tuned RF Val PR AUC: 0.16141081824916093\n",
      "Tuned RF Test PR AUC: 0.17326309785507252\n"
     ]
    }
   ],
   "source": [
    "rf_tuned = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=17,\n",
    "    min_samples_leaf=33,\n",
    "    max_features=0.2435,\n",
    "    max_samples=0.6308,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "rf_tuned.fit(train[features], train[label])\n",
    "\n",
    "train_preds = rf_tuned.predict_proba(train[features])[:, 1]\n",
    "val_preds = rf_tuned.predict_proba(val[features])[:, 1]\n",
    "test_preds = rf_tuned.predict_proba(test[features])[:, 1]\n",
    "\n",
    "train_pr = average_precision_score(train[label], train_preds)\n",
    "val_pr = average_precision_score(val[label], val_preds)\n",
    "test_pr = average_precision_score(test[label], test_preds)\n",
    "\n",
    "print('Tuned RF Train PR AUC:', train_pr)\n",
    "print('Tuned RF Val PR AUC:', val_pr)\n",
    "print('Tuned RF Test PR AUC:', test_pr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Validation PR AUC has improved from 0.128 to 0.161 which is a good sign. We can also see much less overfitting, since we're now controlling the complexity of individual trees. In other words, we've added bias to our model, which made it less prone to overfitting. This has in turn improved the generalisability of our model which made it more performant on unseen data. Keep this balance in mind, when tuning your models - **you want your model to be generalisable, but you also want it to be complex enough to learn from data**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GBT based models (XGBoost, LightGBM, CatBoost) have all more or less converged at this point. So, pick your favourite and tune the hell out of it. My go-to facourite is LightGBM though, so I'll stick with it for this tutorial. Tuning GBTs is a bit more complex than Random Forest models, but it's nothing too complicated to be honest. At first, let's consider the available parameters.<br><br> **Note:** there are many more parameters available, but the ones you see below are the ones I usually tune. For a full list, see [here](https://lightgbm.readthedocs.io/en/latest/Parameters.html).\n",
    "\n",
    "### Gradient Boosting Parameters\n",
    "These parameters control how the gradient boosting algorithm will work e.g. how long will the training take.\n",
    "* learning_rate - how much each learned tree changes the output. Higher means faster training but less accurate models.\n",
    "* n_estimators - number of trees to build. Higher means lower bias. The optimal number is tightly linked with the `learning_rate`. Lower learning rate will require more trees to be built.\n",
    "\n",
    "### Indivudal tree parameters\n",
    "These parameters control the complexity of individual trees.\n",
    "#### Tree complexity:\n",
    "* num_leaves - maximum number of leaves per tree. LGBM is building its trees leaf-wise, so this is the main complexity parameter. Higher values mean more variance and less bias.\n",
    "* max_depth - maximum depth of a tree. You can also control the total depth of a tree. Optimal number will depend on the number of leaves, so read the discussion [here](https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html#:~:text=num_leaves.%20This%20is,than%20depth%2Dwise.).\n",
    "* min_child_samples - minimum number of samples in a leaf. This parameter is very important to control overfitting and its optimal value depends on the number of training samples and num_leaves. Larger values mean more bias, so less overfitting. For larger datasets, setting it to 100s or even 1000s should work well. Small datasets will require smaller number since we still want our trees to build.\n",
    "\n",
    "#### Bagging parameters:\n",
    "* subsample - ratio of samples used when constructing a tree. Larger values make the trees build faster since you're using less data. Additionally, it should improve generalisability of your model since every tree will be trained on different data. Optimal value will depend on the number of samples. With large data, setting it to the range [0.5 - 0.8] should work well. For smaller datasets, don't use it. \n",
    "* colsample_bytree - ratio of features when constructing a tree. Optimal number depends on number of features. I prefer to set it to a range between [0.6 - 0.9] when the number of features is < 20. With more than 20 features, range of [0.2 - 0.5] should work well.\n",
    "#### Control Overfitting:\n",
    "* reg_lambda - L2 regularisation parameter. This simply adds more regularisation to make trees shallower. Increases bias.\n",
    "\n",
    "<br>\n",
    "With this long introduction out of the way, let's build our baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base LGBM PR AUC: 0.16157203528200753\n"
     ]
    }
   ],
   "source": [
    "lgb = LGBMClassifier()\n",
    "lgb.fit(train[features], train[label])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base LGBM Train PR AUC: 0.28191799077519847\n",
      "Base LGBM Val PR AUC: 0.16157203528200753\n"
     ]
    }
   ],
   "source": [
    "lgb_base_preds_train = lgb.predict_proba(train[features])[:, 1]\n",
    "lgb_base_preds_val = lgb.predict_proba(val[features])[:, 1]\n",
    "pr_auc_lgb_base_train = average_precision_score(train[label], lgb_base_preds_train)\n",
    "pr_auc_lgb_base_val = average_precision_score(val[label], lgb_base_preds_val)\n",
    "\n",
    "print('Base LGBM Train PR AUC:', pr_auc_lgb_base_train)\n",
    "print('Base LGBM Val PR AUC:', pr_auc_lgb_base_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of the box, the model performs much better than RF. It overfits less, and the inference speed is also faster. This is due to the fact that the default hyperparameters set in LGBM are already quite good. However, an easy improvement to make is to:\n",
    "* Use early stopping\n",
    "* Use lower learning rate (and hence more trees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of trees and learning rate (with early stopping)\n",
    "Let's set:\n",
    "* Learning reate to `0.01`\n",
    "* Number of estimators to `10,000` with early stopping of `30`\n",
    "\n",
    "This means that we'll keep training until the validation score stops improving for 30 rounds. Hence, even though we've set our `n_estimators` so high, it will most likely never reach it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0529607\n",
      "[200]\tvalid_0's binary_logloss: 0.0503429\n",
      "[300]\tvalid_0's binary_logloss: 0.049285\n",
      "[400]\tvalid_0's binary_logloss: 0.0487125\n",
      "[500]\tvalid_0's binary_logloss: 0.0483604\n",
      "[600]\tvalid_0's binary_logloss: 0.0481839\n",
      "[700]\tvalid_0's binary_logloss: 0.0480711\n",
      "[800]\tvalid_0's binary_logloss: 0.0479972\n",
      "[900]\tvalid_0's binary_logloss: 0.0479354\n",
      "[1000]\tvalid_0's binary_logloss: 0.0478877\n",
      "Early stopping, best iteration is:\n",
      "[1048]\tvalid_0's binary_logloss: 0.0478709\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(learning_rate=0.01, n_estimators=10000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LGBMClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(learning_rate=0.01, n_estimators=10000)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(learning_rate=0.01, n_estimators=10000)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_full = LGBMClassifier(n_estimators=10000, learning_rate=0.01)\n",
    "lgb_full.fit(\n",
    "    train[features],\n",
    "    train[label],\n",
    "    eval_set=[(val[features], val[label])],\n",
    "    callbacks=[log_evaluation(period=100), early_stopping(30)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fully Trained Train LGBM PR AUC: 0.28482254647122535\n",
      "Fully Trained Val LGBM PR AUC: 0.18970866397418748\n"
     ]
    }
   ],
   "source": [
    "lgb_full_preds_train = lgb_full.predict_proba(train[features])[:, 1]\n",
    "lgb_full_preds_val = lgb_full.predict_proba(val[features])[:, 1]\n",
    "pr_auc_lgb_full_train = average_precision_score(train[label], lgb_full_preds_train)\n",
    "pr_auc_lgb_full_val = average_precision_score(val[label], lgb_full_preds_val)\n",
    "\n",
    "print('Fully Trained Train LGBM PR AUC:', pr_auc_lgb_full_train)\n",
    "print('Fully Trained Val LGBM PR AUC:', pr_auc_lgb_full_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've managed to increase the validation score without increasing the degree of overfitting. <br> **Important Note:** If you're short on time, doing this type of \"optimisation\" is your best bet at improve the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's tune all the other parameters mentioned above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning\n",
    "One interesting property of GBTs is that good parameters generalise across learning rates (mostly). I've discovered this idea in this [blog](https://randomrealizations.com/posts/xgboost-parameter-tuning-with-optuna/) and it has worked well for me in my work as well. So, in the tuning below, I'll be using learning rate of `0.1`, still with early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:02:58,435] A new study created in memory with name: no-name-3073ce0a-ac3f-4d0f-82e4-f11d47b21757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0480609\n",
      "Early stopping, best iteration is:\n",
      "[76]\tvalid_0's binary_logloss: 0.0480269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:03:02,106] Trial 0 finished with value: 0.18816359973694827 and parameters: {'num_leaves': 75, 'min_child_samples': 49, 'colsample_bytree': 0.6568390725374141, 'subsample': 0.8989992784449374, 'reg_lambda': 7.458158058628989}. Best is trial 0 with value: 0.18816359973694827.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.047654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:03:06,197] Trial 1 finished with value: 0.19562628201135104 and parameters: {'num_leaves': 79, 'min_child_samples': 91, 'colsample_bytree': 0.25310613836086315, 'subsample': 0.9415792042416072, 'reg_lambda': 5.830627729938015}. Best is trial 1 with value: 0.19562628201135104.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's binary_logloss: 0.0476325\n",
      "Training until validation scores don't improve for 30 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:03:12,346] Trial 2 finished with value: 0.1731203003897835 and parameters: {'num_leaves': 225, 'min_child_samples': 77, 'colsample_bytree': 0.5485563696205832, 'subsample': 0.8563972883068809, 'reg_lambda': 2.481542581698845}. Best is trial 1 with value: 0.19562628201135104.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's binary_logloss: 0.0487904\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0482098\n",
      "Early stopping, best iteration is:\n",
      "[102]\tvalid_0's binary_logloss: 0.0481827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:03:18,544] Trial 3 finished with value: 0.1854599327583057 and parameters: {'num_leaves': 134, 'min_child_samples': 30, 'colsample_bytree': 0.28056908946099735, 'subsample': 0.9165327927329201, 'reg_lambda': 2.7169551875483036}. Best is trial 1 with value: 0.19562628201135104.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0489182\n",
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's binary_logloss: 0.0487963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:03:25,685] Trial 4 finished with value: 0.1706834710390068 and parameters: {'num_leaves': 225, 'min_child_samples': 51, 'colsample_bytree': 0.6374155176970647, 'subsample': 0.8848078145594518, 'reg_lambda': 3.5401163547956305}. Best is trial 1 with value: 0.19562628201135104.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:03:30,402] Trial 5 finished with value: 0.17520767931405706 and parameters: {'num_leaves': 142, 'min_child_samples': 72, 'colsample_bytree': 0.6632130719169284, 'subsample': 0.786663936094754, 'reg_lambda': 2.8352733469190037}. Best is trial 1 with value: 0.19562628201135104.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's binary_logloss: 0.0486302\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.047757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:03:33,631] Trial 6 finished with value: 0.19124269515239578 and parameters: {'num_leaves': 29, 'min_child_samples': 98, 'colsample_bytree': 0.5845597792076674, 'subsample': 0.9221131010439376, 'reg_lambda': 3.0455912458017673}. Best is trial 1 with value: 0.19562628201135104.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[146]\tvalid_0's binary_logloss: 0.0477295\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0480016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:03:38,897] Trial 7 finished with value: 0.18695537721712913 and parameters: {'num_leaves': 114, 'min_child_samples': 37, 'colsample_bytree': 0.47602807745296827, 'subsample': 0.9542888758680156, 'reg_lambda': 8.161230499455751}. Best is trial 1 with value: 0.19562628201135104.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[87]\tvalid_0's binary_logloss: 0.0479264\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0479063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:03:43,687] Trial 8 finished with value: 0.18801049995978905 and parameters: {'num_leaves': 110, 'min_child_samples': 80, 'colsample_bytree': 0.3934997546479947, 'subsample': 0.9892372085134977, 'reg_lambda': 6.976954651996453}. Best is trial 1 with value: 0.19562628201135104.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[86]\tvalid_0's binary_logloss: 0.0478599\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0475887\n",
      "[200]\tvalid_0's binary_logloss: 0.0474886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:03:46,796] Trial 9 finished with value: 0.19370524634557656 and parameters: {'num_leaves': 18, 'min_child_samples': 17, 'colsample_bytree': 0.4271077403285033, 'subsample': 0.8587524008630498, 'reg_lambda': 7.226887645181006}. Best is trial 1 with value: 0.19562628201135104.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[211]\tvalid_0's binary_logloss: 0.0474657\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0481236\n",
      "Early stopping, best iteration is:\n",
      "[148]\tvalid_0's binary_logloss: 0.0478012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:03:55,277] Trial 10 finished with value: 0.19431860539518628 and parameters: {'num_leaves': 178, 'min_child_samples': 99, 'colsample_bytree': 0.10435352561968941, 'subsample': 0.7200312214096583, 'reg_lambda': 9.97416266003526}. Best is trial 1 with value: 0.19562628201135104.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0481442\n",
      "[200]\tvalid_0's binary_logloss: 0.0477466\n",
      "Early stopping, best iteration is:\n",
      "[183]\tvalid_0's binary_logloss: 0.0477101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:04:05,469] Trial 11 finished with value: 0.19594196009349915 and parameters: {'num_leaves': 176, 'min_child_samples': 100, 'colsample_bytree': 0.11350869852871501, 'subsample': 0.7170998167860583, 'reg_lambda': 9.886577342225253}. Best is trial 11 with value: 0.19594196009349915.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0486184\n",
      "Early stopping, best iteration is:\n",
      "[131]\tvalid_0's binary_logloss: 0.0484307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:04:14,757] Trial 12 finished with value: 0.18360476044883145 and parameters: {'num_leaves': 184, 'min_child_samples': 91, 'colsample_bytree': 0.12769791581090115, 'subsample': 0.7874887005208144, 'reg_lambda': 0.774715995951877}. Best is trial 11 with value: 0.19594196009349915.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0476336\n",
      "Early stopping, best iteration is:\n",
      "[152]\tvalid_0's binary_logloss: 0.047486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:04:19,293] Trial 13 finished with value: 0.19149996324284893 and parameters: {'num_leaves': 59, 'min_child_samples': 62, 'colsample_bytree': 0.20718687489288343, 'subsample': 0.7210830600248983, 'reg_lambda': 5.155260978684704}. Best is trial 11 with value: 0.19594196009349915.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0482502\n",
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's binary_logloss: 0.048222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:04:29,149] Trial 14 finished with value: 0.18630081160539247 and parameters: {'num_leaves': 256, 'min_child_samples': 85, 'colsample_bytree': 0.28293342245399844, 'subsample': 0.8018574299118013, 'reg_lambda': 9.452363984460801}. Best is trial 11 with value: 0.19594196009349915.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0477719\n",
      "Early stopping, best iteration is:\n",
      "[159]\tvalid_0's binary_logloss: 0.0476305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:04:34,663] Trial 15 finished with value: 0.1904008305650176 and parameters: {'num_leaves': 74, 'min_child_samples': 67, 'colsample_bytree': 0.20195783927308436, 'subsample': 0.9937712337868849, 'reg_lambda': 5.44776857329194}. Best is trial 11 with value: 0.19594196009349915.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0480097\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's binary_logloss: 0.0479651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:04:41,656] Trial 16 finished with value: 0.18728953333768195 and parameters: {'num_leaves': 167, 'min_child_samples': 89, 'colsample_bytree': 0.32915906195643174, 'subsample': 0.7511918485495612, 'reg_lambda': 8.823539504491565}. Best is trial 11 with value: 0.19594196009349915.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0479031\n",
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's binary_logloss: 0.0477594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:04:47,845] Trial 17 finished with value: 0.19405770762512117 and parameters: {'num_leaves': 102, 'min_child_samples': 98, 'colsample_bytree': 0.18599201848465285, 'subsample': 0.8225699871139102, 'reg_lambda': 6.389025534347315}. Best is trial 11 with value: 0.19594196009349915.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0482233\n",
      "Early stopping, best iteration is:\n",
      "[112]\tvalid_0's binary_logloss: 0.048197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:04:55,334] Trial 18 finished with value: 0.1875780956668682 and parameters: {'num_leaves': 158, 'min_child_samples': 59, 'colsample_bytree': 0.2698520608454421, 'subsample': 0.9630173832255234, 'reg_lambda': 3.971751884429503}. Best is trial 11 with value: 0.19594196009349915.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0479624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:04:58,973] Trial 19 finished with value: 0.19080075187237627 and parameters: {'num_leaves': 46, 'min_child_samples': 86, 'colsample_bytree': 0.1632185031452959, 'subsample': 0.7501435279355184, 'reg_lambda': 0.05220507994950818}. Best is trial 11 with value: 0.19594196009349915.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[149]\tvalid_0's binary_logloss: 0.0478219\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0482032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:05:05,850] Trial 20 finished with value: 0.1853477863129483 and parameters: {'num_leaves': 200, 'min_child_samples': 74, 'colsample_bytree': 0.35471855368495253, 'subsample': 0.9489489075234863, 'reg_lambda': 6.098306630540126}. Best is trial 11 with value: 0.19594196009349915.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's binary_logloss: 0.0480853\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0481037\n",
      "Early stopping, best iteration is:\n",
      "[163]\tvalid_0's binary_logloss: 0.047766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:05:15,829] Trial 21 finished with value: 0.19518628727453874 and parameters: {'num_leaves': 192, 'min_child_samples': 99, 'colsample_bytree': 0.11291850268136286, 'subsample': 0.7000404659623689, 'reg_lambda': 9.43012129489173}. Best is trial 11 with value: 0.19594196009349915.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.04815\n",
      "Early stopping, best iteration is:\n",
      "[164]\tvalid_0's binary_logloss: 0.0478378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:05:26,546] Trial 22 finished with value: 0.19237824083634864 and parameters: {'num_leaves': 208, 'min_child_samples': 100, 'colsample_bytree': 0.10071465179544598, 'subsample': 0.7040841189454411, 'reg_lambda': 8.503660273358513}. Best is trial 11 with value: 0.19594196009349915.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.047801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:05:32,656] Trial 23 finished with value: 0.19353788440546038 and parameters: {'num_leaves': 147, 'min_child_samples': 92, 'colsample_bytree': 0.25092935422763674, 'subsample': 0.74375768432506, 'reg_lambda': 9.913996053368628}. Best is trial 11 with value: 0.19594196009349915.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's binary_logloss: 0.0477756\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0481209\n",
      "Early stopping, best iteration is:\n",
      "[129]\tvalid_0's binary_logloss: 0.0480208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:05:42,481] Trial 24 finished with value: 0.19194314663243578 and parameters: {'num_leaves': 202, 'min_child_samples': 81, 'colsample_bytree': 0.15528353518843555, 'subsample': 0.7012539431367131, 'reg_lambda': 9.031975197400001}. Best is trial 11 with value: 0.19594196009349915.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0476862\n",
      "Early stopping, best iteration is:\n",
      "[128]\tvalid_0's binary_logloss: 0.0476409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:05:48,057] Trial 25 finished with value: 0.19534742882240802 and parameters: {'num_leaves': 91, 'min_child_samples': 92, 'colsample_bytree': 0.2272925080166387, 'subsample': 0.8194766994460668, 'reg_lambda': 7.951406353570409}. Best is trial 11 with value: 0.19594196009349915.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0476243\n",
      "Early stopping, best iteration is:\n",
      "[112]\tvalid_0's binary_logloss: 0.0475848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:05:53,111] Trial 26 finished with value: 0.19665242999912372 and parameters: {'num_leaves': 91, 'min_child_samples': 91, 'colsample_bytree': 0.2335059208345142, 'subsample': 0.8303255768491047, 'reg_lambda': 7.921111391679843}. Best is trial 26 with value: 0.19665242999912372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0479494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:05:57,391] Trial 27 finished with value: 0.1875707827382676 and parameters: {'num_leaves': 88, 'min_child_samples': 71, 'colsample_bytree': 0.3351662248156921, 'subsample': 0.8727101185052513, 'reg_lambda': 4.331316607821282}. Best is trial 26 with value: 0.19665242999912372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's binary_logloss: 0.047931\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0481099\n",
      "[200]\tvalid_0's binary_logloss: 0.0477712\n",
      "Early stopping, best iteration is:\n",
      "[192]\tvalid_0's binary_logloss: 0.0477588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:06:06,321] Trial 28 finished with value: 0.19239592060977367 and parameters: {'num_leaves': 118, 'min_child_samples': 84, 'colsample_bytree': 0.14973126289284708, 'subsample': 0.8321701946755186, 'reg_lambda': 7.874579455815559}. Best is trial 26 with value: 0.19665242999912372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0477197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:06:10,740] Trial 29 finished with value: 0.18921873116036583 and parameters: {'num_leaves': 76, 'min_child_samples': 47, 'colsample_bytree': 0.3005038914822833, 'subsample': 0.89176714496269, 'reg_lambda': 6.19280432144264}. Best is trial 26 with value: 0.19665242999912372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's binary_logloss: 0.0477019\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0478815\n",
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's binary_logloss: 0.0478266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:06:16,415] Trial 30 finished with value: 0.1928302608436954 and parameters: {'num_leaves': 126, 'min_child_samples': 10, 'colsample_bytree': 0.22659567923042914, 'subsample': 0.924292601985294, 'reg_lambda': 6.987285286791725}. Best is trial 26 with value: 0.19665242999912372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0476266\n",
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's binary_logloss: 0.0475772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:06:21,610] Trial 31 finished with value: 0.1959629201546524 and parameters: {'num_leaves': 95, 'min_child_samples': 93, 'colsample_bytree': 0.2373960731328771, 'subsample': 0.8224996966254782, 'reg_lambda': 8.150344794741525}. Best is trial 26 with value: 0.19665242999912372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0476618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:06:25,757] Trial 32 finished with value: 0.18802338884568015 and parameters: {'num_leaves': 57, 'min_child_samples': 93, 'colsample_bytree': 0.37758103209195193, 'subsample': 0.7734193381650218, 'reg_lambda': 7.85104654032825}. Best is trial 26 with value: 0.19665242999912372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[127]\tvalid_0's binary_logloss: 0.047659\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0478764\n",
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's binary_logloss: 0.0478554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:06:31,037] Trial 33 finished with value: 0.19099212057809956 and parameters: {'num_leaves': 89, 'min_child_samples': 78, 'colsample_bytree': 0.43847186529925275, 'subsample': 0.8396168424096135, 'reg_lambda': 8.742232939910146}. Best is trial 26 with value: 0.19665242999912372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0476397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:06:35,460] Trial 34 finished with value: 0.1944602902887227 and parameters: {'num_leaves': 76, 'min_child_samples': 87, 'colsample_bytree': 0.2358072402272901, 'subsample': 0.8115041284506668, 'reg_lambda': 5.790564591876672}. Best is trial 26 with value: 0.19665242999912372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[113]\tvalid_0's binary_logloss: 0.0475695\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0480343\n",
      "Early stopping, best iteration is:\n",
      "[129]\tvalid_0's binary_logloss: 0.0478875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:06:54,996] Trial 35 finished with value: 0.192143456781243 and parameters: {'num_leaves': 135, 'min_child_samples': 94, 'colsample_bytree': 0.1798827721537271, 'subsample': 0.8503295153500171, 'reg_lambda': 7.343956308126982}. Best is trial 26 with value: 0.19665242999912372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0477616\n",
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's binary_logloss: 0.0477511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:07:00,368] Trial 36 finished with value: 0.18969132150963952 and parameters: {'num_leaves': 100, 'min_child_samples': 82, 'colsample_bytree': 0.3032980503713066, 'subsample': 0.8673912925430457, 'reg_lambda': 6.650235711740304}. Best is trial 26 with value: 0.19665242999912372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0476243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:07:26,011] Trial 37 finished with value: 0.1939660895767822 and parameters: {'num_leaves': 44, 'min_child_samples': 67, 'colsample_bytree': 0.5311619460385717, 'subsample': 0.9068734053930462, 'reg_lambda': 9.278904312748741}. Best is trial 26 with value: 0.19665242999912372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[112]\tvalid_0's binary_logloss: 0.0475926\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0476357\n",
      "Early stopping, best iteration is:\n",
      "[105]\tvalid_0's binary_logloss: 0.0476148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:07:29,929] Trial 38 finished with value: 0.19285281052051453 and parameters: {'num_leaves': 64, 'min_child_samples': 34, 'colsample_bytree': 0.252661068514962, 'subsample': 0.7762972252467353, 'reg_lambda': 4.726211575907507}. Best is trial 26 with value: 0.19665242999912372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0481975\n",
      "[200]\tvalid_0's binary_logloss: 0.0478145\n",
      "Early stopping, best iteration is:\n",
      "[192]\tvalid_0's binary_logloss: 0.0477936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:07:38,953] Trial 39 finished with value: 0.19078414684545636 and parameters: {'num_leaves': 122, 'min_child_samples': 76, 'colsample_bytree': 0.1322252498061724, 'subsample': 0.8808828941527151, 'reg_lambda': 8.413384464835547}. Best is trial 26 with value: 0.19665242999912372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0480456\n",
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's binary_logloss: 0.0480187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:07:45,348] Trial 40 finished with value: 0.18682278069497865 and parameters: {'num_leaves': 153, 'min_child_samples': 94, 'colsample_bytree': 0.2071734527844446, 'subsample': 0.7985516207840748, 'reg_lambda': 7.563049352704395}. Best is trial 26 with value: 0.19665242999912372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0477722\n",
      "Early stopping, best iteration is:\n",
      "[114]\tvalid_0's binary_logloss: 0.0477477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:07:50,539] Trial 41 finished with value: 0.19255887226160273 and parameters: {'num_leaves': 93, 'min_child_samples': 95, 'colsample_bytree': 0.2773658056676617, 'subsample': 0.8227544656085496, 'reg_lambda': 7.995341716512363}. Best is trial 26 with value: 0.19665242999912372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0476633\n",
      "Early stopping, best iteration is:\n",
      "[114]\tvalid_0's binary_logloss: 0.0476112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:07:56,326] Trial 42 finished with value: 0.19609691507259616 and parameters: {'num_leaves': 108, 'min_child_samples': 89, 'colsample_bytree': 0.22741775288752042, 'subsample': 0.8371843477353897, 'reg_lambda': 6.8835285899859056}. Best is trial 26 with value: 0.19665242999912372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0478336\n",
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's binary_logloss: 0.047806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:08:02,027] Trial 43 finished with value: 0.18935626386311052 and parameters: {'num_leaves': 108, 'min_child_samples': 88, 'colsample_bytree': 0.31572554838568034, 'subsample': 0.8406041079015062, 'reg_lambda': 6.778943767953004}. Best is trial 26 with value: 0.19665242999912372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:08:06,347] Trial 44 finished with value: 0.1831479338148106 and parameters: {'num_leaves': 128, 'min_child_samples': 89, 'colsample_bytree': 0.6873690703395657, 'subsample': 0.8515877831379212, 'reg_lambda': 7.474357238375016}. Best is trial 26 with value: 0.19665242999912372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's binary_logloss: 0.0482763\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0482159\n",
      "Early stopping, best iteration is:\n",
      "[138]\tvalid_0's binary_logloss: 0.0481345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:08:17,932] Trial 45 finished with value: 0.18943175837822251 and parameters: {'num_leaves': 229, 'min_child_samples': 45, 'colsample_bytree': 0.18763619261931283, 'subsample': 0.9768389114946295, 'reg_lambda': 5.639259505845469}. Best is trial 26 with value: 0.19665242999912372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0479583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:08:22,485] Trial 46 finished with value: 0.18722331374282455 and parameters: {'num_leaves': 113, 'min_child_samples': 96, 'colsample_bytree': 0.35837934872376903, 'subsample': 0.928297391452707, 'reg_lambda': 1.7550694844162553}. Best is trial 26 with value: 0.19665242999912372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's binary_logloss: 0.0479085\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0479466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:08:26,484] Trial 47 finished with value: 0.1833217278249188 and parameters: {'num_leaves': 81, 'min_child_samples': 81, 'colsample_bytree': 0.42514746226106, 'subsample': 0.9041633797922822, 'reg_lambda': 4.8233607193117365}. Best is trial 26 with value: 0.19665242999912372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[87]\tvalid_0's binary_logloss: 0.0479361\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0482174\n",
      "Early stopping, best iteration is:\n",
      "[131]\tvalid_0's binary_logloss: 0.0479971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:08:35,238] Trial 48 finished with value: 0.19117793769712335 and parameters: {'num_leaves': 172, 'min_child_samples': 22, 'colsample_bytree': 0.13750168250625885, 'subsample': 0.8063199975028743, 'reg_lambda': 7.18109283442152}. Best is trial 26 with value: 0.19665242999912372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0476152\n",
      "Early stopping, best iteration is:\n",
      "[146]\tvalid_0's binary_logloss: 0.0475673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:08:40,275] Trial 49 finished with value: 0.19396081722247427 and parameters: {'num_leaves': 68, 'min_child_samples': 100, 'colsample_bytree': 0.2581422793737673, 'subsample': 0.7867010523260304, 'reg_lambda': 9.730116938060945}. Best is trial 26 with value: 0.19665242999912372.\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    num_leaves = trial.suggest_int('num_leaves', 16, 256)\n",
    "    min_child_samples = trial.suggest_int(\"min_child_samples\", 10, 100)\n",
    "    colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.1, 0.7)\n",
    "    subsample = trial.suggest_float(\"subsample\", 0.7, 1)\n",
    "    reg_lambda = trial.suggest_float(\"reg_lambda\", 0, 10)\n",
    "\n",
    "    lgb = LGBMClassifier(\n",
    "        n_estimators=100000,\n",
    "        learning_rate=0.1,\n",
    "        num_leaves=num_leaves,\n",
    "        min_child_samples=min_child_samples,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        subsample=subsample,\n",
    "        reg_lambda=reg_lambda,\n",
    "        verbose=-1\n",
    "    )\n",
    "\n",
    "    lgb.fit(\n",
    "        train[features],\n",
    "        train[label],\n",
    "        eval_set=[(val[features], val[label])],\n",
    "        callbacks=[log_evaluation(period=100), early_stopping(30)]\n",
    "    )\n",
    "\n",
    "    lgb_preds = lgb.predict_proba(val[features])[:, 1]\n",
    "    pr = average_precision_score(val[label], lgb_preds)\n",
    "\n",
    "    return pr\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "Value: 0.1967\n",
      "Params: \n",
      "    num_leaves: 91\n",
      "    min_child_samples: 91\n",
      "    colsample_bytree: 0.2335059208345142\n",
      "    subsample: 0.8303255768491047\n",
      "    reg_lambda: 7.921111391679843\n"
     ]
    }
   ],
   "source": [
    "# Print the best parameters found\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"Value: {:.4f}\".format(trial.value))\n",
    "\n",
    "print(\"Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal parameters are fit, and they look quite sensible. Number of leaves being 91 does seem a bit high though, but the tree growth is controlled by other parameters so it's nothing to worry about. Hence, it's time to start reducing the learning rate. Usually, I'd just drop it to 0.01 or something similar, but below you can see the results for a variety of learning rates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact of Learning Rate\n",
    "The usual rule is: **Lower learning rate == better model & slower training**. Let's see if this assumption holds for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    \"num_leaves\": 91,\n",
    "    \"min_child_samples\": 91,\n",
    "    \"colsample_bytree\": 0.2335059208345142,\n",
    "    \"subsample\": 0.8303255768491047,\n",
    "    \"reg_lambda\": 7.921111391679843\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's binary_logloss: 0.0490437\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's binary_logloss: 0.048122\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0476243\n",
      "Early stopping, best iteration is:\n",
      "[112]\tvalid_0's binary_logloss: 0.0475848\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.048229\n",
      "[200]\tvalid_0's binary_logloss: 0.0475131\n",
      "Early stopping, best iteration is:\n",
      "[221]\tvalid_0's binary_logloss: 0.0474943\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0503432\n",
      "[200]\tvalid_0's binary_logloss: 0.0481688\n",
      "[300]\tvalid_0's binary_logloss: 0.0476193\n",
      "[400]\tvalid_0's binary_logloss: 0.0474296\n",
      "Early stopping, best iteration is:\n",
      "[438]\tvalid_0's binary_logloss: 0.0473977\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0547601\n",
      "[200]\tvalid_0's binary_logloss: 0.0512481\n",
      "[300]\tvalid_0's binary_logloss: 0.0496239\n",
      "[400]\tvalid_0's binary_logloss: 0.0486926\n",
      "[500]\tvalid_0's binary_logloss: 0.0481611\n",
      "[600]\tvalid_0's binary_logloss: 0.0478459\n",
      "[700]\tvalid_0's binary_logloss: 0.0476477\n",
      "[800]\tvalid_0's binary_logloss: 0.0475161\n",
      "[900]\tvalid_0's binary_logloss: 0.0474206\n",
      "[1000]\tvalid_0's binary_logloss: 0.0473745\n",
      "[1100]\tvalid_0's binary_logloss: 0.0473598\n",
      "Early stopping, best iteration is:\n",
      "[1151]\tvalid_0's binary_logloss: 0.0473554\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0581684\n",
      "[200]\tvalid_0's binary_logloss: 0.0547361\n",
      "[300]\tvalid_0's binary_logloss: 0.0526889\n",
      "[400]\tvalid_0's binary_logloss: 0.0512847\n",
      "[500]\tvalid_0's binary_logloss: 0.0502991\n",
      "[600]\tvalid_0's binary_logloss: 0.0496006\n",
      "[700]\tvalid_0's binary_logloss: 0.0490935\n",
      "[800]\tvalid_0's binary_logloss: 0.0486987\n",
      "[900]\tvalid_0's binary_logloss: 0.0483893\n",
      "[1000]\tvalid_0's binary_logloss: 0.0481486\n",
      "[1100]\tvalid_0's binary_logloss: 0.0479707\n",
      "[1200]\tvalid_0's binary_logloss: 0.047832\n",
      "[1300]\tvalid_0's binary_logloss: 0.0477113\n",
      "[1400]\tvalid_0's binary_logloss: 0.0476217\n",
      "[1500]\tvalid_0's binary_logloss: 0.0475522\n",
      "[1600]\tvalid_0's binary_logloss: 0.0474964\n",
      "[1700]\tvalid_0's binary_logloss: 0.0474558\n",
      "[1800]\tvalid_0's binary_logloss: 0.0474287\n",
      "[1900]\tvalid_0's binary_logloss: 0.0474029\n",
      "[2000]\tvalid_0's binary_logloss: 0.0473832\n",
      "[2100]\tvalid_0's binary_logloss: 0.0473672\n",
      "[2200]\tvalid_0's binary_logloss: 0.0473532\n",
      "Early stopping, best iteration is:\n",
      "[2247]\tvalid_0's binary_logloss: 0.0473471\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0627748\n",
      "[200]\tvalid_0's binary_logloss: 0.0613506\n",
      "[300]\tvalid_0's binary_logloss: 0.0601449\n",
      "[400]\tvalid_0's binary_logloss: 0.0590909\n",
      "[500]\tvalid_0's binary_logloss: 0.0581871\n",
      "[600]\tvalid_0's binary_logloss: 0.0573661\n",
      "[700]\tvalid_0's binary_logloss: 0.0566347\n",
      "[800]\tvalid_0's binary_logloss: 0.0559634\n",
      "[900]\tvalid_0's binary_logloss: 0.0553401\n",
      "[1000]\tvalid_0's binary_logloss: 0.0547891\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1100]\tvalid_0's binary_logloss: 0.0543127\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1200]\tvalid_0's binary_logloss: 0.0538849\n",
      "[1300]\tvalid_0's binary_logloss: 0.053453\n",
      "[1400]\tvalid_0's binary_logloss: 0.0530615\n",
      "[1500]\tvalid_0's binary_logloss: 0.0527041\n",
      "[1600]\tvalid_0's binary_logloss: 0.0523746\n",
      "[1700]\tvalid_0's binary_logloss: 0.0520624\n",
      "[1800]\tvalid_0's binary_logloss: 0.051786\n",
      "[1900]\tvalid_0's binary_logloss: 0.0515249\n",
      "[2000]\tvalid_0's binary_logloss: 0.0512791\n",
      "[2100]\tvalid_0's binary_logloss: 0.0510522\n",
      "[2200]\tvalid_0's binary_logloss: 0.0508442\n",
      "[2300]\tvalid_0's binary_logloss: 0.0506472\n",
      "[2400]\tvalid_0's binary_logloss: 0.0504711\n",
      "[2500]\tvalid_0's binary_logloss: 0.0503022\n",
      "[2600]\tvalid_0's binary_logloss: 0.0501415\n",
      "[2700]\tvalid_0's binary_logloss: 0.0499902\n",
      "[2800]\tvalid_0's binary_logloss: 0.0498547\n",
      "[2900]\tvalid_0's binary_logloss: 0.0497266\n",
      "[3000]\tvalid_0's binary_logloss: 0.0496042\n",
      "[3100]\tvalid_0's binary_logloss: 0.0494841\n",
      "[3200]\tvalid_0's binary_logloss: 0.0493735\n",
      "[3300]\tvalid_0's binary_logloss: 0.0492716\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3400]\tvalid_0's binary_logloss: 0.0491716\n",
      "[3500]\tvalid_0's binary_logloss: 0.0490779\n",
      "[3600]\tvalid_0's binary_logloss: 0.048992\n",
      "[3700]\tvalid_0's binary_logloss: 0.0489119\n",
      "[3800]\tvalid_0's binary_logloss: 0.048834\n",
      "[3900]\tvalid_0's binary_logloss: 0.048759\n",
      "[4000]\tvalid_0's binary_logloss: 0.0486873\n",
      "[4100]\tvalid_0's binary_logloss: 0.0486181\n",
      "[4200]\tvalid_0's binary_logloss: 0.0485569\n",
      "[4300]\tvalid_0's binary_logloss: 0.0484983\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4400]\tvalid_0's binary_logloss: 0.0484389\n",
      "[4500]\tvalid_0's binary_logloss: 0.0483822\n",
      "[4600]\tvalid_0's binary_logloss: 0.0483313\n",
      "[4700]\tvalid_0's binary_logloss: 0.0482809\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4800]\tvalid_0's binary_logloss: 0.0482345\n",
      "[4900]\tvalid_0's binary_logloss: 0.048191\n",
      "[5000]\tvalid_0's binary_logloss: 0.0481501\n",
      "[5100]\tvalid_0's binary_logloss: 0.0481069\n",
      "[5200]\tvalid_0's binary_logloss: 0.0480666\n",
      "[5300]\tvalid_0's binary_logloss: 0.0480327\n",
      "[5400]\tvalid_0's binary_logloss: 0.0479975\n",
      "[5500]\tvalid_0's binary_logloss: 0.047964\n",
      "[5600]\tvalid_0's binary_logloss: 0.047933\n",
      "[5700]\tvalid_0's binary_logloss: 0.0479028\n",
      "[5800]\tvalid_0's binary_logloss: 0.0478755\n",
      "[5900]\tvalid_0's binary_logloss: 0.0478479\n",
      "[6000]\tvalid_0's binary_logloss: 0.0478211\n",
      "[6100]\tvalid_0's binary_logloss: 0.0477977\n",
      "[6200]\tvalid_0's binary_logloss: 0.0477743\n",
      "[6300]\tvalid_0's binary_logloss: 0.0477517\n",
      "[6400]\tvalid_0's binary_logloss: 0.0477296\n",
      "[6500]\tvalid_0's binary_logloss: 0.0477106\n",
      "[6600]\tvalid_0's binary_logloss: 0.0476916\n",
      "[6700]\tvalid_0's binary_logloss: 0.0476724\n",
      "[6800]\tvalid_0's binary_logloss: 0.0476544\n",
      "[6900]\tvalid_0's binary_logloss: 0.047638\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7000]\tvalid_0's binary_logloss: 0.0476206\n",
      "[7100]\tvalid_0's binary_logloss: 0.0476031\n",
      "[7200]\tvalid_0's binary_logloss: 0.0475869\n",
      "[7300]\tvalid_0's binary_logloss: 0.0475718\n",
      "[7400]\tvalid_0's binary_logloss: 0.047556\n",
      "[7500]\tvalid_0's binary_logloss: 0.0475437\n",
      "[7600]\tvalid_0's binary_logloss: 0.0475316\n",
      "[7700]\tvalid_0's binary_logloss: 0.0475195\n",
      "[7800]\tvalid_0's binary_logloss: 0.0475081\n",
      "[7900]\tvalid_0's binary_logloss: 0.0474985\n",
      "[8000]\tvalid_0's binary_logloss: 0.0474893\n",
      "[8100]\tvalid_0's binary_logloss: 0.04748\n",
      "[8200]\tvalid_0's binary_logloss: 0.0474703\n",
      "[8300]\tvalid_0's binary_logloss: 0.0474603\n",
      "[8400]\tvalid_0's binary_logloss: 0.0474517\n",
      "[8500]\tvalid_0's binary_logloss: 0.0474442\n",
      "[8600]\tvalid_0's binary_logloss: 0.0474358\n",
      "[8700]\tvalid_0's binary_logloss: 0.0474284\n",
      "[8800]\tvalid_0's binary_logloss: 0.0474215\n",
      "[8900]\tvalid_0's binary_logloss: 0.0474151\n",
      "[9000]\tvalid_0's binary_logloss: 0.0474095\n",
      "[9100]\tvalid_0's binary_logloss: 0.0474049\n",
      "[9200]\tvalid_0's binary_logloss: 0.0473988\n",
      "[9300]\tvalid_0's binary_logloss: 0.0473932\n",
      "[9400]\tvalid_0's binary_logloss: 0.0473884\n",
      "[9500]\tvalid_0's binary_logloss: 0.0473826\n",
      "[9600]\tvalid_0's binary_logloss: 0.0473767\n",
      "[9700]\tvalid_0's binary_logloss: 0.0473719\n",
      "[9800]\tvalid_0's binary_logloss: 0.0473693\n",
      "[9900]\tvalid_0's binary_logloss: 0.0473665\n",
      "[10000]\tvalid_0's binary_logloss: 0.0473618\n",
      "[10100]\tvalid_0's binary_logloss: 0.0473573\n",
      "Early stopping, best iteration is:\n",
      "[10124]\tvalid_0's binary_logloss: 0.0473563\n"
     ]
    }
   ],
   "source": [
    "lrs = [0.5, 0.3, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\n",
    "best_iters = []\n",
    "prs = []\n",
    "\n",
    "for lr in lrs:\n",
    "    lgb_tuned = LGBMClassifier(\n",
    "        n_estimators=100000,\n",
    "        learning_rate=lr,\n",
    "        verbose=0,\n",
    "        force_row_wise=True,\n",
    "        **best_params\n",
    "        #**study.best_trial.params\n",
    "    )\n",
    "\n",
    "    lgb_tuned.fit(\n",
    "        train[features],\n",
    "        train[label],\n",
    "        eval_set=[(val[features], val[label])],\n",
    "        callbacks=[log_evaluation(period=100), early_stopping(30)]\n",
    "    )\n",
    "\n",
    "    val_preds = lgb_tuned.predict_proba(val[features])[:, 1]\n",
    "    val_pr = average_precision_score(val[label], val_preds)\n",
    "    best_iters.append(lgb_tuned.best_iteration_)\n",
    "    prs.append(val_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg class=\"main-svg\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"700\" height=\"500\" style=\"\" viewBox=\"0 0 700 500\"><rect x=\"0\" y=\"0\" width=\"700\" height=\"500\" style=\"fill: rgb(255, 255, 255); fill-opacity: 1;\"/><defs id=\"defs-e2cc2c\"><g class=\"clips\"><clipPath id=\"clipe2cc2cxyplot\" class=\"plotclip\"><rect width=\"398.56\" height=\"320\"/></clipPath><clipPath id=\"clipe2cc2cxy2plot\" class=\"plotclip\"><rect width=\"398.56\" height=\"320\"/></clipPath><clipPath class=\"axesclip\" id=\"clipe2cc2cx\"><rect x=\"80\" y=\"0\" width=\"398.56\" height=\"500\"/></clipPath><clipPath class=\"axesclip\" id=\"clipe2cc2cy\"><rect x=\"0\" y=\"100\" width=\"700\" height=\"320\"/></clipPath><clipPath class=\"axesclip\" id=\"clipe2cc2cxy\"><rect x=\"80\" y=\"100\" width=\"398.56\" height=\"320\"/></clipPath><clipPath class=\"axesclip\" id=\"clipe2cc2cy2\"><rect x=\"0\" y=\"100\" width=\"700\" height=\"320\"/></clipPath><clipPath class=\"axesclip\" id=\"clipe2cc2cxy2\"><rect x=\"80\" y=\"100\" width=\"398.56\" height=\"320\"/></clipPath></g><g class=\"gradients\"/><g class=\"patterns\"/></defs><g class=\"bglayer\"><rect class=\"bg\" x=\"80\" y=\"100\" width=\"398.56\" height=\"320\" style=\"fill: rgb(229, 236, 246); fill-opacity: 1; stroke-width: 0;\"/></g><g class=\"layer-below\"><g class=\"imagelayer\"/><g class=\"shapelayer\"/></g><g class=\"cartesianlayer\"><g class=\"subplot xy\"><g class=\"layer-subplot\"><g class=\"shapelayer\"/><g class=\"imagelayer\"/></g><g class=\"minor-gridlayer\"><g class=\"x\"/><g class=\"y\"/><g class=\"y2\"/></g><g class=\"gridlayer\"><g class=\"x\"><path class=\"xgrid crisp\" transform=\"translate(173.36,0)\" d=\"M0,100v320\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(243.74,0)\" d=\"M0,100v320\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(314.12,0)\" d=\"M0,100v320\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(384.5,0)\" d=\"M0,100v320\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(454.88,0)\" d=\"M0,100v320\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/></g><g class=\"y\"><path class=\"ygrid crisp\" transform=\"translate(0,345.28)\" d=\"M80,0h398.56\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,289.76)\" d=\"M80,0h398.56\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,234.24)\" d=\"M80,0h398.56\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,178.70999999999998)\" d=\"M80,0h398.56\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,123.19)\" d=\"M80,0h398.56\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/></g><g class=\"y2\"><path class=\"y2grid crisp\" transform=\"translate(0,358.95)\" d=\"M80,0h398.56\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"y2grid crisp\" transform=\"translate(0,297.9)\" d=\"M80,0h398.56\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"y2grid crisp\" transform=\"translate(0,236.85)\" d=\"M80,0h398.56\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"y2grid crisp\" transform=\"translate(0,175.8)\" d=\"M80,0h398.56\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"y2grid crisp\" transform=\"translate(0,114.75)\" d=\"M80,0h398.56\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/></g></g><g class=\"zerolinelayer\"><path class=\"xzl zl crisp\" transform=\"translate(102.97,0)\" d=\"M0,100v320\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 2px;\"/><path class=\"yzl zl crisp\" transform=\"translate(0,400.81)\" d=\"M80,0h398.56\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 2px;\"/></g><path class=\"xlines-below\"/><path class=\"ylines-below\"/><g class=\"overlines-below\"><path class=\"xy2-x\"/><path class=\"xy2-y\"/></g><g class=\"xaxislayer-below\"/><g class=\"yaxislayer-below\"/><g class=\"overaxes-below\"><g class=\"xy2-x\"/><g class=\"xy2-y\"/></g><g class=\"plot\" transform=\"translate(80,100)\" clip-path=\"url(#clipe2cc2cxyplot)\"><g class=\"scatterlayer mlayer\"><g class=\"trace scatter tracea75aea\" style=\"stroke-miterlimit: 2; opacity: 1;\"><g class=\"fills\"/><g class=\"errorbars\"/><g class=\"lines\"><path class=\"js-line\" d=\"M374.88,300.25L234.12,299.94L93.36,297.7L58.16,294.67L40.57,288.65L30.01,268.85L26.49,238.43L23.68,19.75\" style=\"vector-effect: none; fill: none; stroke: rgb(99, 110, 250); stroke-opacity: 1; stroke-width: 2px; opacity: 1;\"/></g><g class=\"points\"><path class=\"point\" transform=\"translate(374.88,300.25)\" d=\"M3,0A3,3 0 1,1 0,-3A3,3 0 0,1 3,0Z\" style=\"opacity: 1; stroke-width: 0px; fill: rgb(99, 110, 250); fill-opacity: 1;\"/><path class=\"point\" transform=\"translate(234.12,299.94)\" d=\"M3,0A3,3 0 1,1 0,-3A3,3 0 0,1 3,0Z\" style=\"opacity: 1; stroke-width: 0px; fill: rgb(99, 110, 250); fill-opacity: 1;\"/><path class=\"point\" transform=\"translate(93.36,297.7)\" d=\"M3,0A3,3 0 1,1 0,-3A3,3 0 0,1 3,0Z\" style=\"opacity: 1; stroke-width: 0px; fill: rgb(99, 110, 250); fill-opacity: 1;\"/><path class=\"point\" transform=\"translate(58.16,294.67)\" d=\"M3,0A3,3 0 1,1 0,-3A3,3 0 0,1 3,0Z\" style=\"opacity: 1; stroke-width: 0px; fill: rgb(99, 110, 250); fill-opacity: 1;\"/><path class=\"point\" transform=\"translate(40.57,288.65)\" d=\"M3,0A3,3 0 1,1 0,-3A3,3 0 0,1 3,0Z\" style=\"opacity: 1; stroke-width: 0px; fill: rgb(99, 110, 250); fill-opacity: 1;\"/><path class=\"point\" transform=\"translate(30.01,268.85)\" d=\"M3,0A3,3 0 1,1 0,-3A3,3 0 0,1 3,0Z\" style=\"opacity: 1; stroke-width: 0px; fill: rgb(99, 110, 250); fill-opacity: 1;\"/><path class=\"point\" transform=\"translate(26.49,238.43)\" d=\"M3,0A3,3 0 1,1 0,-3A3,3 0 0,1 3,0Z\" style=\"opacity: 1; stroke-width: 0px; fill: rgb(99, 110, 250); fill-opacity: 1;\"/><path class=\"point\" transform=\"translate(23.68,19.75)\" d=\"M3,0A3,3 0 1,1 0,-3A3,3 0 0,1 3,0Z\" style=\"opacity: 1; stroke-width: 0px; fill: rgb(99, 110, 250); fill-opacity: 1;\"/></g><g class=\"text\"/></g></g></g><g class=\"overplot\"><g class=\"xy2\" transform=\"translate(80,100)\" clip-path=\"url(#clipe2cc2cxy2plot)\"><g class=\"scatterlayer mlayer\"><g class=\"trace scatter trace55bdec\" style=\"stroke-miterlimit: 2; opacity: 1;\"><g class=\"fills\"/><g class=\"errorbars\"/><g class=\"lines\"><path class=\"js-line\" d=\"M374.88,300.25L234.12,163.48L93.36,55.63L58.16,65.55L40.57,52.4L30.01,33.37L26.49,22.57L23.68,19.75\" style=\"vector-effect: none; fill: none; stroke: rgb(239, 85, 59); stroke-opacity: 1; stroke-width: 2px; opacity: 1;\"/></g><g class=\"points\"><path class=\"point\" transform=\"translate(374.88,300.25)\" d=\"M3,0A3,3 0 1,1 0,-3A3,3 0 0,1 3,0Z\" style=\"opacity: 1; stroke-width: 0px; fill: rgb(239, 85, 59); fill-opacity: 1;\"/><path class=\"point\" transform=\"translate(234.12,163.48)\" d=\"M3,0A3,3 0 1,1 0,-3A3,3 0 0,1 3,0Z\" style=\"opacity: 1; stroke-width: 0px; fill: rgb(239, 85, 59); fill-opacity: 1;\"/><path class=\"point\" transform=\"translate(93.36,55.63)\" d=\"M3,0A3,3 0 1,1 0,-3A3,3 0 0,1 3,0Z\" style=\"opacity: 1; stroke-width: 0px; fill: rgb(239, 85, 59); fill-opacity: 1;\"/><path class=\"point\" transform=\"translate(58.16,65.55)\" d=\"M3,0A3,3 0 1,1 0,-3A3,3 0 0,1 3,0Z\" style=\"opacity: 1; stroke-width: 0px; fill: rgb(239, 85, 59); fill-opacity: 1;\"/><path class=\"point\" transform=\"translate(40.57,52.4)\" d=\"M3,0A3,3 0 1,1 0,-3A3,3 0 0,1 3,0Z\" style=\"opacity: 1; stroke-width: 0px; fill: rgb(239, 85, 59); fill-opacity: 1;\"/><path class=\"point\" transform=\"translate(30.01,33.37)\" d=\"M3,0A3,3 0 1,1 0,-3A3,3 0 0,1 3,0Z\" style=\"opacity: 1; stroke-width: 0px; fill: rgb(239, 85, 59); fill-opacity: 1;\"/><path class=\"point\" transform=\"translate(26.49,22.57)\" d=\"M3,0A3,3 0 1,1 0,-3A3,3 0 0,1 3,0Z\" style=\"opacity: 1; stroke-width: 0px; fill: rgb(239, 85, 59); fill-opacity: 1;\"/><path class=\"point\" transform=\"translate(23.68,19.75)\" d=\"M3,0A3,3 0 1,1 0,-3A3,3 0 0,1 3,0Z\" style=\"opacity: 1; stroke-width: 0px; fill: rgb(239, 85, 59); fill-opacity: 1;\"/></g><g class=\"text\"/></g></g></g></g><path class=\"xlines-above crisp\" d=\"M0,0\" style=\"fill: none;\"/><path class=\"ylines-above crisp\" d=\"M0,0\" style=\"fill: none;\"/><g class=\"overlines-above\"><path class=\"xy2-x crisp\" d=\"M0,0\" style=\"fill: none;\"/><path class=\"xy2-y crisp\" d=\"M0,0\" style=\"fill: none;\"/></g><g class=\"xaxislayer-above\"><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"433\" transform=\"translate(102.97,0)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\">0</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"433\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(173.36,0)\">0.1</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"433\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(243.74,0)\">0.2</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"433\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(314.12,0)\">0.3</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"433\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(384.5,0)\">0.4</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"433\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(454.88,0)\">0.5</text></g></g><g class=\"yaxislayer-above\"><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" transform=\"translate(0,400.81)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\">0</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(0,345.28)\">2k</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(0,289.76)\">4k</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(0,234.24)\">6k</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(0,178.70999999999998)\">8k</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(0,123.19)\">10k</text></g></g><g class=\"overaxes-above\"><g class=\"xy2-x\"/><g class=\"xy2-y\"><g class=\"y2tick\"><text text-anchor=\"start\" x=\"479.56\" y=\"4.199999999999999\" transform=\"translate(0,420)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\">0.175</text></g><g class=\"y2tick\"><text text-anchor=\"start\" x=\"479.56\" y=\"4.199999999999999\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(0,358.95)\">0.18</text></g><g class=\"y2tick\"><text text-anchor=\"start\" x=\"479.56\" y=\"4.199999999999999\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(0,297.9)\">0.185</text></g><g class=\"y2tick\"><text text-anchor=\"start\" x=\"479.56\" y=\"4.199999999999999\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(0,236.85)\">0.19</text></g><g class=\"y2tick\"><text text-anchor=\"start\" x=\"479.56\" y=\"4.199999999999999\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(0,175.8)\">0.195</text></g><g class=\"y2tick\"><text text-anchor=\"start\" x=\"479.56\" y=\"4.199999999999999\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(0,114.75)\">0.2</text></g></g></g></g><g class=\"subplot xy2\"/></g><g class=\"polarlayer\"/><g class=\"smithlayer\"/><g class=\"ternarylayer\"/><g class=\"geolayer\"/><g class=\"funnelarealayer\"/><g class=\"pielayer\"/><g class=\"iciclelayer\"/><g class=\"treemaplayer\"/><g class=\"sunburstlayer\"/><g class=\"glimages\"/><defs id=\"topdefs-e2cc2c\"><g class=\"clips\"/><clipPath id=\"legende2cc2c\"><rect width=\"176\" height=\"48\" x=\"0\" y=\"0\"/></clipPath></defs><g class=\"layer-above\"><g class=\"imagelayer\"/><g class=\"shapelayer\"/></g><g class=\"infolayer\"><g class=\"legend\" pointer-events=\"all\" transform=\"translate(512.48,100)\"><rect class=\"bg\" shape-rendering=\"crispEdges\" style=\"stroke: rgb(68, 68, 68); stroke-opacity: 1; fill: rgb(255, 255, 255); fill-opacity: 1; stroke-width: 0px;\" width=\"176\" height=\"48\" x=\"0\" y=\"0\"/><g class=\"scrollbox\" transform=\"\" clip-path=\"url(#legende2cc2c)\"><g class=\"groups\"><g class=\"traces\" transform=\"translate(0,14.5)\" style=\"opacity: 1;\"><text class=\"legendtext\" text-anchor=\"start\" x=\"40\" y=\"4.680000000000001\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">Optimal Tree Number</text><g class=\"layers\" style=\"opacity: 1;\"><g class=\"legendfill\"/><g class=\"legendlines\"><path class=\"js-line\" d=\"M5,0h30\" style=\"fill: none; stroke: rgb(99, 110, 250); stroke-opacity: 1; stroke-width: 2px;\"/></g><g class=\"legendsymbols\"><g class=\"legendpoints\"><path class=\"scatterpts\" transform=\"translate(20,0)\" d=\"M3,0A3,3 0 1,1 0,-3A3,3 0 0,1 3,0Z\" style=\"opacity: 1; stroke-width: 0px; fill: rgb(99, 110, 250); fill-opacity: 1;\"/></g></g></g><rect class=\"legendtoggle\" x=\"0\" y=\"-9.5\" width=\"170.40625\" height=\"19\" style=\"fill: rgb(0, 0, 0); fill-opacity: 0;\"/></g><g class=\"traces\" transform=\"translate(0,33.5)\" style=\"opacity: 1;\"><text class=\"legendtext\" text-anchor=\"start\" x=\"40\" y=\"4.680000000000001\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">PR AUC</text><g class=\"layers\" style=\"opacity: 1;\"><g class=\"legendfill\"/><g class=\"legendlines\"><path class=\"js-line\" d=\"M5,0h30\" style=\"fill: none; stroke: rgb(239, 85, 59); stroke-opacity: 1; stroke-width: 2px;\"/></g><g class=\"legendsymbols\"><g class=\"legendpoints\"><path class=\"scatterpts\" transform=\"translate(20,0)\" d=\"M3,0A3,3 0 1,1 0,-3A3,3 0 0,1 3,0Z\" style=\"opacity: 1; stroke-width: 0px; fill: rgb(239, 85, 59); fill-opacity: 1;\"/></g></g></g><rect class=\"legendtoggle\" x=\"0\" y=\"-9.5\" width=\"170.40625\" height=\"19\" style=\"fill: rgb(0, 0, 0); fill-opacity: 0;\"/></g></g></g><rect class=\"scrollbar\" rx=\"20\" ry=\"3\" width=\"0\" height=\"0\" style=\"fill: rgb(128, 139, 164); fill-opacity: 1;\" x=\"0\" y=\"0\"/></g><g class=\"g-gtitle\"><text class=\"gtitle\" x=\"35\" y=\"50\" text-anchor=\"start\" dy=\"0em\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 17px; fill: rgb(42, 63, 95); opacity: 1; font-weight: normal; white-space: pre;\">Valdiation PR AUC &amp; Tree Number vs Learning Rate</text></g><g class=\"g-xtitle\"><text class=\"xtitle\" x=\"279.28\" y=\"459.8\" text-anchor=\"middle\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 14px; fill: rgb(42, 63, 95); opacity: 1; font-weight: normal; white-space: pre;\">Learning Rate</text></g><g class=\"g-ytitle\"><text class=\"ytitle\" transform=\"rotate(-90,32.340625,260)\" x=\"32.340625\" y=\"260\" text-anchor=\"middle\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 14px; fill: rgb(42, 63, 95); opacity: 1; font-weight: normal; white-space: pre;\">Number of Iterations (Trees) to Train</text></g><g class=\"g-y2title\"><text class=\"y2title\" transform=\"rotate(-90,538.753125,260)\" x=\"538.753125\" y=\"260\" text-anchor=\"middle\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 14px; fill: rgb(42, 63, 95); opacity: 1; font-weight: normal; white-space: pre;\">PR AUC Score</text></g></g></svg>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create figure with secondary y-axis\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "# Add traces\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=lrs, y=best_iters, name=\"Optimal Tree Number\"),\n",
    "    secondary_y=False,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=lrs, y=prs, name=\"PR AUC\"),\n",
    "    secondary_y=True,\n",
    ")\n",
    "\n",
    "# Add figure title\n",
    "fig.update_layout(\n",
    "    title_text=\"Valdiation PR AUC & Tree Number vs Learning Rate\"\n",
    ")\n",
    "\n",
    "# Set x-axis title\n",
    "fig.update_xaxes(title_text=\"Learning Rate\")\n",
    "\n",
    "# Set y-axes titles\n",
    "fig.update_yaxes(title_text=\"Number of Iterations (Trees) to Train\", secondary_y=False)\n",
    "fig.update_yaxes(title_text=\"PR AUC Score\", secondary_y=True)\n",
    "\n",
    "fig.show(renderer='svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, lower learning rate indeed results in more iterations and higher PR AUC. From the plot above, the optimal learning rate would actually be `0.005` since it has almost the same PR AUC as `0.001` but it takes 5 times less iterations to train. If you have time, do perform this type of analysis, since it will ensure that you deploy the simplest yet performant model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023762 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0581684\n",
      "[200]\tvalid_0's binary_logloss: 0.0547361\n",
      "[300]\tvalid_0's binary_logloss: 0.0526889\n",
      "[400]\tvalid_0's binary_logloss: 0.0512847\n",
      "[500]\tvalid_0's binary_logloss: 0.0502991\n",
      "[600]\tvalid_0's binary_logloss: 0.0496006\n",
      "[700]\tvalid_0's binary_logloss: 0.0490935\n",
      "[800]\tvalid_0's binary_logloss: 0.0486987\n",
      "[900]\tvalid_0's binary_logloss: 0.0483893\n",
      "[1000]\tvalid_0's binary_logloss: 0.0481486\n",
      "[1100]\tvalid_0's binary_logloss: 0.0479707\n",
      "[1200]\tvalid_0's binary_logloss: 0.047832\n",
      "[1300]\tvalid_0's binary_logloss: 0.0477113\n",
      "[1400]\tvalid_0's binary_logloss: 0.0476217\n",
      "[1500]\tvalid_0's binary_logloss: 0.0475522\n",
      "[1600]\tvalid_0's binary_logloss: 0.0474964\n",
      "[1700]\tvalid_0's binary_logloss: 0.0474558\n",
      "[1800]\tvalid_0's binary_logloss: 0.0474287\n",
      "[1900]\tvalid_0's binary_logloss: 0.0474029\n",
      "[2000]\tvalid_0's binary_logloss: 0.0473832\n",
      "[2100]\tvalid_0's binary_logloss: 0.0473672\n",
      "[2200]\tvalid_0's binary_logloss: 0.0473532\n",
      "Early stopping, best iteration is:\n",
      "[2247]\tvalid_0's binary_logloss: 0.0473471\n",
      "Tuned LGBM Train PR AUC: 0.31901514608622794\n",
      "Tuned LGBM Val PR AUC: 0.19935987075864675\n",
      "Tuned LGBM Test PR AUC: 0.19951770572453778\n"
     ]
    }
   ],
   "source": [
    "lgb_tuned = LGBMClassifier(\n",
    "        n_estimators=100000,\n",
    "        learning_rate=0.005,\n",
    "        verbose=0,\n",
    "        **study.best_trial.params\n",
    ")\n",
    "\n",
    "lgb_tuned.fit(\n",
    "    train[features],\n",
    "    train[label],\n",
    "    eval_set=[(val[features], val[label])],\n",
    "    callbacks=[log_evaluation(period=100), early_stopping(30)],\n",
    ")\n",
    "\n",
    "train_preds = lgb_tuned.predict_proba(train[features])[:, 1]\n",
    "val_preds = lgb_tuned.predict_proba(val[features])[:, 1]\n",
    "test_preds = lgb_tuned.predict_proba(test[features])[:, 1]\n",
    "\n",
    "train_pr = average_precision_score(train[label], train_preds)\n",
    "val_pr = average_precision_score(val[label], val_preds)\n",
    "test_pr = average_precision_score(test[label], test_preds)\n",
    "\n",
    "print('Tuned LGBM Train PR AUC:', train_pr)\n",
    "print('Tuned LGBM Val PR AUC:', val_pr)\n",
    "print('Tuned LGBM Test PR AUC:', test_pr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this final model, we've achieved great improvements to PR AUC (1.23x). The final model is quite complex and large, yet the degree of overfitting is acceptable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "Overall, we've explored how to do hyperparameter tuning for 2 ensamble tree based models - Random Forest and Gradient Boosting (LightGBM). We've used Optuna for this and expored how different HPs affest the bias variance tradeoff. Below you can find some points to keep in mind while tuning your models:\n",
    "* Always think of HP tuning as the process of discovering the optimal bias/variance tradeoff for the model\n",
    "* Always know the key parameters to tune - what they are and what they do. If you're unsure about the theory behind them, read the documentation or watch tutorials (e.g. [StatsQuest](https://www.youtube.com/@statquest) has great series about RF and GBTs)\n",
    "* Always sense check your HPs after tuning them. E.g `max_depth` of 1 is never a good idea, so there might be some issues with your pipeline. That's why it's important to know what the parameters mean\n",
    "* **Never put too much time into HP tuning**. You're better off spending more time on feature engineering to improve the model results. HP tuning will allow you to squeeze the bits of performance but the increase in performance is really marginal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
