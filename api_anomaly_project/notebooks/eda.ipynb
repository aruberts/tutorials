{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "The main objectives for this notebook are:\n",
    "* Explore the clean dataset by performing univariate analysis\n",
    "* Investiage the relationships between your features and your target by perofrming bivariate and multivariate analyses\n",
    "* Extract relevant insights to share with business stakeholders\n",
    "* Understand steps that will be required for ML pre-processing\n",
    "\n",
    "The skills that you need to showcase:\n",
    "* Your ability to raise hypotheses, answer them, and interpret the results\n",
    "* You data wrangling and visualisation skills\n",
    "\n",
    "## How to stand out?\n",
    "1. Use non-Pandas DataFrame library like Polars or PySpark\n",
    "2. Use interactive plots (e.g. Plotly) for visualisations (don't forget to render your notebooks as HTML)\n",
    "    - Your visualisations should have some additional formatting\n",
    "3. Write clear insights after every section of the analysis\n",
    "4. Use well-written and documented utility functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "# Path needs to be added manually to read from another folder\n",
    "path2add = os.path.normpath(os.path.abspath(os.path.join(os.path.dirname('__file__'), os.path.pardir, 'utils')))\n",
    "if (not (path2add in sys.path)) :\n",
    "    sys.path.append(path2add)\n",
    "    \n",
    "import polars as pl\n",
    "import plotly.express as px\n",
    "from visualisations import bar_plot, proportion_plot, boxplot_by_bin_with_target\n",
    "# etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pl.read_csv(\"../data/supervised_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Analysis\n",
    "This section goes through the avilable columns and plots them  to see the distributions, outliers, etc. This is done to introduce the data set and to get you familiar with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_plot(data, \"ip_type\", \"IP Type Counts\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "* There are just two ip types - `default` and `datacenter`, with `datacenter` being the most frequent one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features vs Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section performs a bi-variate analysis by looking at the distributions of normal vs outliers. This can help in determining what data and feature selection to perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion_plot(data, \"ip_type\", \"classification\", \"Behaviour Type by Source\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "* If the acitivty comes from a `datacenter`, it's guaranteed to be an outlier\n",
    "\n",
    "**Impact**\n",
    "* The dataset needs to be filtered to include only `default` traffic since we don't need a model to classify `datacenter` traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypotheses\n",
    "This section is for you to showcase your analytical skill and to ask interesting questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are longer sessions with high speed inter API calls more anomalous?\n",
    "It's usually the case that if a lot of events happen in a short period of time - this might signal bot or other malicious activity. Let's see if it's the case for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_by_bin_with_target(\n",
    "    data = data,\n",
    "    column_to_bin = \"sequence_length(count)\",\n",
    "    numeric_column = \"inter_api_access_duration(sec)\",\n",
    "    target = \"classification\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "* Outliers have faster inter API duration than normal traffic\n",
    "* In the shortest sequence length, the difference in inter API duration is not as drastic as it is for longer sequences\n",
    "\n",
    "**Insights**\n",
    "* Longer sequences with faster inter API access duration are more likely to be anomalous\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Main Insights\n",
    "* Most of the traffic comes from the default source, only 9% comes from datacenters\n",
    "* All the datacenter traffic is considered to be anomalous\n",
    "* Longer sequences with faster inter API access ruations are more likely to be anomalous\n",
    "\n",
    "### Implications for Modelling\n",
    "* Dataset needs to be filter to include only the `default` source type\n",
    "* Interaction between `sequence_length` and `inter_api_duration` needs to be either manually encoded, or a tree-based model needs to be used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
